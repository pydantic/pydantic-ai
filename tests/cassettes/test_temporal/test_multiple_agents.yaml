interactions:
- request:
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate, br, zstd
      connection:
      - keep-alive
      content-length:
      - '113'
      content-type:
      - application/json
      cookie:
      - __cf_bm=NxrWoKCYu2KiRs8tbspHMzkaXG_UUFqBkmLKyjI.Lqc-1770130408-1.0.1.1-dPkfGMzzyEyaIRIncD7d8KLbDuj.0.RJy88ySIx4SsDe.f8YpkfxM5S_nSogj_EWjxnz12hKMAGVaf3rA57wNgtX4fmLdZEpaIY_y5_Rgy4;
        _cfuvid=EvmN3DH0eEp_eQlg32YUzBc0ZLJvIp_pSEHKEL3K0k4-1770130408454-0.0.1.1-604800000
      host:
      - api.openai.com
    method: POST
    parsed_body:
      messages:
      - content: What is the capital of Mexico?
        role: user
      model: gpt-4o
      stream: false
    uri: https://api.openai.com/v1/chat/completions
  response:
    headers:
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      connection:
      - keep-alive
      content-length:
      - '669'
      content-type:
      - application/json
      openai-processing-ms:
      - '466'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=31536000; includeSubDomains; preload
      transfer-encoding:
      - chunked
    parsed_body:
      choices:
      - finish_reason: stop
        index: 0
        logprobs: null
        message:
          annotations: []
          content: The capital of Mexico is Mexico City.
          refusal: null
          role: assistant
      created: 1770130418
      id: chatcmpl-D5C4Y5WLXOhA0NPuGm2d5q6mFOpqD
      model: gpt-4o-2024-08-06
      object: chat.completion
      service_tier: default
      system_fingerprint: fp_fa7f5b168b
      usage:
        completion_tokens: 8
        completion_tokens_details:
          accepted_prediction_tokens: 0
          audio_tokens: 0
          reasoning_tokens: 0
          rejected_prediction_tokens: 0
        prompt_tokens: 14
        prompt_tokens_details:
          audio_tokens: 0
          cached_tokens: 0
        total_tokens: 22
    status:
      code: 200
      message: OK
- request:
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate, br, zstd
      connection:
      - keep-alive
      content-length:
      - '5797'
      content-type:
      - application/json
      cookie:
      - __cf_bm=NxrWoKCYu2KiRs8tbspHMzkaXG_UUFqBkmLKyjI.Lqc-1770130408-1.0.1.1-dPkfGMzzyEyaIRIncD7d8KLbDuj.0.RJy88ySIx4SsDe.f8YpkfxM5S_nSogj_EWjxnz12hKMAGVaf3rA57wNgtX4fmLdZEpaIY_y5_Rgy4;
        _cfuvid=EvmN3DH0eEp_eQlg32YUzBc0ZLJvIp_pSEHKEL3K0k4-1770130408454-0.0.1.1-604800000
      host:
      - api.openai.com
    method: POST
    parsed_body:
      messages:
      - content: 'Tell me: the capital of the country; the weather there; the product name'
        role: user
      model: gpt-4o
      stream: true
      stream_options:
        include_usage: true
      tool_choice: required
      tools:
      - function:
          description: ''
          name: get_weather
          parameters:
            additionalProperties: false
            properties:
              city:
                type: string
            required:
            - city
            type: object
          strict: true
        type: function
      - function:
          description: ''
          name: get_country
          parameters:
            additionalProperties: false
            properties: {}
            type: object
        type: function
      - function:
          description: "Convert Celsius to Fahrenheit.\n\n    Args:\n        celsius: Temperature in Celsius\n\n    Returns:\n
            \       Temperature in Fahrenheit\n    "
          name: celsius_to_fahrenheit
          parameters:
            additionalProperties: false
            properties:
              celsius:
                type: number
            required:
            - celsius
            type: object
          strict: true
        type: function
      - function:
          description: "Get the weather forecast for a location.\n\n    Args:\n        location: The location to get the weather
            forecast for.\n\n    Returns:\n        The weather forecast for the location.\n    "
          name: get_weather_forecast
          parameters:
            additionalProperties: false
            properties:
              location:
                type: string
            required:
            - location
            type: object
          strict: true
        type: function
      - function:
          description: ''
          name: get_image_resource
          parameters:
            additionalProperties: false
            properties: {}
            type: object
        type: function
      - function:
          description: ''
          name: get_image_resource_link
          parameters:
            additionalProperties: false
            properties: {}
            type: object
        type: function
      - function:
          description: ''
          name: get_audio_resource
          parameters:
            additionalProperties: false
            properties: {}
            type: object
        type: function
      - function:
          description: ''
          name: get_audio_resource_link
          parameters:
            additionalProperties: false
            properties: {}
            type: object
        type: function
      - function:
          description: ''
          name: get_product_name
          parameters:
            additionalProperties: false
            properties: {}
            type: object
        type: function
      - function:
          description: ''
          name: get_product_name_link
          parameters:
            additionalProperties: false
            properties: {}
            type: object
        type: function
      - function:
          description: ''
          name: get_image
          parameters:
            additionalProperties: false
            properties: {}
            type: object
        type: function
      - function:
          description: ''
          name: get_dict
          parameters:
            additionalProperties: false
            properties: {}
            type: object
        type: function
      - function:
          description: ''
          name: get_unstructured_dict
          parameters:
            additionalProperties: false
            properties: {}
            type: object
        type: function
      - function:
          description: ''
          name: get_error
          parameters:
            additionalProperties: false
            properties:
              value:
                default: false
                type: boolean
            type: object
        type: function
      - function:
          description: ''
          name: get_none
          parameters:
            additionalProperties: false
            properties: {}
            type: object
        type: function
      - function:
          description: ''
          name: get_multiple_items
          parameters:
            additionalProperties: false
            properties: {}
            type: object
        type: function
      - function:
          description: "Get the current log level.\n\n    Returns:\n        The current log level.\n    "
          name: get_log_level
          parameters:
            additionalProperties: false
            properties: {}
            type: object
        type: function
      - function:
          description: "Echo the run context.\n\n    Args:\n        ctx: Context object containing request and session information.\n\n
            \   Returns:\n        Dictionary with an echo message and the deps.\n    "
          name: echo_deps
          parameters:
            additionalProperties: false
            properties: {}
            type: object
        type: function
      - function:
          description: Use sampling callback.
          name: use_sampling
          parameters:
            additionalProperties: false
            properties:
              foo:
                type: string
            required:
            - foo
            type: object
          strict: true
        type: function
      - function:
          description: "Get information about the connected MCP client.\n\n    Returns:\n        Dictionary with client info
            (name, version, etc.) or None if not available.\n    "
          name: get_client_info
          parameters:
            additionalProperties: false
            properties: {}
            type: object
        type: function
      - function:
          description: Use elicitation callback to ask the user a question.
          name: use_elicitation
          parameters:
            additionalProperties: false
            properties:
              question:
                type: string
            required:
            - question
            type: object
          strict: true
        type: function
      - function:
          description: Enable the hidden tool, triggering a ToolListChangedNotification.
          name: enable_hidden_tool
          parameters:
            additionalProperties: false
            properties: {}
            type: object
        type: function
      - function:
          description: ''
          name: external
          parameters:
            additionalProperties: false
            properties: {}
            type: object
        type: function
      - function:
          description: The final response which ends this conversation
          name: final_result
          parameters:
            $defs:
              Answer:
                additionalProperties: false
                properties:
                  answer:
                    type: string
                  label:
                    type: string
                required:
                - label
                - answer
                type: object
            additionalProperties: false
            properties:
              answers:
                items:
                  $ref: '#/$defs/Answer'
                type: array
            required:
            - answers
            type: object
          strict: true
        type: function
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: |+
        data: {"id":"chatcmpl-D5C4c8cGO0Hhb8egYqfCp6NZPMh3y","object":"chat.completion.chunk","created":1770130422,"model":"gpt-4o-2024-08-06","service_tier":"default","system_fingerprint":"fp_fa7f5b168b","usage":null,"choices":[{"index":0,"delta":{"role":"assistant","content":null},"logprobs":null,"finish_reason":null}],"obfuscation":"wVpdJV8sY27"}

        data: {"id":"chatcmpl-D5C4c8cGO0Hhb8egYqfCp6NZPMh3y","object":"chat.completion.chunk","created":1770130422,"model":"gpt-4o-2024-08-06","service_tier":"default","system_fingerprint":"fp_fa7f5b168b","usage":null,"choices":[{"index":0,"delta":{"tool_calls":[{"index":0,"id":"call_X7JX4kRIMCf6MUaQJEOv97Si","type":"function","function":{"name":"get_country","arguments":""}}]},"logprobs":null,"finish_reason":null}],"obfuscation":"AsjKmn3d8i"}

        data: {"id":"chatcmpl-D5C4c8cGO0Hhb8egYqfCp6NZPMh3y","object":"chat.completion.chunk","created":1770130422,"model":"gpt-4o-2024-08-06","service_tier":"default","system_fingerprint":"fp_fa7f5b168b","usage":null,"choices":[{"index":0,"delta":{"tool_calls":[{"index":0,"function":{"arguments":"{}"}}]},"logprobs":null,"finish_reason":null}],"obfuscation":"UAER"}

        data: {"id":"chatcmpl-D5C4c8cGO0Hhb8egYqfCp6NZPMh3y","object":"chat.completion.chunk","created":1770130422,"model":"gpt-4o-2024-08-06","service_tier":"default","system_fingerprint":"fp_fa7f5b168b","usage":null,"choices":[{"index":0,"delta":{"tool_calls":[{"index":1,"id":"call_aS0UBMeZjqCHSIlhXjX5mmqY","type":"function","function":{"name":"get_product_name","arguments":""}}]},"logprobs":null,"finish_reason":null}],"obfuscation":"yLxMg"}

        data: {"id":"chatcmpl-D5C4c8cGO0Hhb8egYqfCp6NZPMh3y","object":"chat.completion.chunk","created":1770130422,"model":"gpt-4o-2024-08-06","service_tier":"default","system_fingerprint":"fp_fa7f5b168b","usage":null,"choices":[{"index":0,"delta":{"tool_calls":[{"index":1,"function":{"arguments":"{}"}}]},"logprobs":null,"finish_reason":null}],"obfuscation":"rDZs"}

        data: {"id":"chatcmpl-D5C4c8cGO0Hhb8egYqfCp6NZPMh3y","object":"chat.completion.chunk","created":1770130422,"model":"gpt-4o-2024-08-06","service_tier":"default","system_fingerprint":"fp_fa7f5b168b","usage":null,"choices":[{"index":0,"delta":{"tool_calls":[{"index":2,"id":"call_qsjUnWAxzY5xpXLGFgb68rN5","type":"function","function":{"name":"get_image","arguments":""}}]},"logprobs":null,"finish_reason":null}],"obfuscation":"7wKfDK6m0jBP"}

        data: {"id":"chatcmpl-D5C4c8cGO0Hhb8egYqfCp6NZPMh3y","object":"chat.completion.chunk","created":1770130422,"model":"gpt-4o-2024-08-06","service_tier":"default","system_fingerprint":"fp_fa7f5b168b","usage":null,"choices":[{"index":0,"delta":{"tool_calls":[{"index":2,"function":{"arguments":"{}"}}]},"logprobs":null,"finish_reason":null}],"obfuscation":"893E"}

        data: {"id":"chatcmpl-D5C4c8cGO0Hhb8egYqfCp6NZPMh3y","object":"chat.completion.chunk","created":1770130422,"model":"gpt-4o-2024-08-06","service_tier":"default","system_fingerprint":"fp_fa7f5b168b","choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"tool_calls"}],"usage":null,"obfuscation":"07G0"}

        data: {"id":"chatcmpl-D5C4c8cGO0Hhb8egYqfCp6NZPMh3y","object":"chat.completion.chunk","created":1770130422,"model":"gpt-4o-2024-08-06","service_tier":"default","system_fingerprint":"fp_fa7f5b168b","choices":[],"usage":{"prompt_tokens":465,"completion_tokens":51,"total_tokens":516,"prompt_tokens_details":{"cached_tokens":0,"audio_tokens":0},"completion_tokens_details":{"reasoning_tokens":0,"audio_tokens":0,"accepted_prediction_tokens":0,"rejected_prediction_tokens":0}},"obfuscation":"dTJTi3c8RB94N"}

        data: [DONE]

    headers:
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      connection:
      - keep-alive
      content-type:
      - text/event-stream; charset=utf-8
      openai-processing-ms:
      - '1362'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=31536000; includeSubDomains; preload
      transfer-encoding:
      - chunked
    status:
      code: 200
      message: OK
version: 1
...
