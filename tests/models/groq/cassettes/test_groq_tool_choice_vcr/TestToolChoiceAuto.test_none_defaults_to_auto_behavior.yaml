interactions:
- request:
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '402'
      content-type:
      - application/json
      host:
      - api.groq.com
    method: POST
    parsed_body:
      messages:
      - content: What's the weather in London?
        role: user
      model: meta-llama/llama-4-scout-17b-16e-instruct
      n: 1
      stream: false
      tool_choice: auto
      tools:
      - function:
          description: Get the current weather for a city.
          name: get_weather
          parameters:
            additionalProperties: false
            properties:
              city:
                type: string
            required:
            - city
            type: object
        type: function
    uri: https://api.groq.com/openai/v1/chat/completions
  response:
    headers:
      alt-svc:
      - h3=":443"; ma=86400
      cache-control:
      - private, max-age=0, no-store, no-cache, must-revalidate
      connection:
      - keep-alive
      content-length:
      - '709'
      content-type:
      - application/json
      strict-transport-security:
      - max-age=15552000
      transfer-encoding:
      - chunked
      vary:
      - Origin
    parsed_body:
      choices:
      - finish_reason: tool_calls
        index: 0
        logprobs: null
        message:
          role: assistant
          tool_calls:
          - function:
              arguments: '{"city":"London"}'
              name: get_weather
            id: vj9mvwsqj
            type: function
      created: 1766183500
      id: chatcmpl-ea816754-0fc3-4e83-ac30-3be5892c69de
      model: meta-llama/llama-4-scout-17b-16e-instruct
      object: chat.completion
      service_tier: on_demand
      system_fingerprint: fp_130a0cd72d
      usage:
        completion_time: 0.073470087
        completion_tokens: 29
        prompt_time: 0.023305456
        prompt_tokens: 717
        queue_time: 0.072935665
        total_time: 0.096775543
        total_tokens: 746
      usage_breakdown: null
      x_groq:
        id: req_01kcwbtyp6fhksxh0ra370vtxs
        seed: 1747933320
    status:
      code: 200
      message: OK
- request:
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '621'
      content-type:
      - application/json
      cookie:
      - __cf_bm=2tz67aDWJ8ZyNhahlWokQq03eptDnWZzTQZXA_svbg0-1766183500-1.0.1.1-pcnV.3A8TENbQCEJvFrMYxMQ6EG0txW5T2g8pm6JoLEvFEdzoWpFVGZuDv0pxE8xOGcX7gvxqeJ8bZVmaOGOBMoG1nKGsBggeV.M7Rt_bx8
      host:
      - api.groq.com
    method: POST
    parsed_body:
      messages:
      - content: What's the weather in London?
        role: user
      - role: assistant
        tool_calls:
        - function:
            arguments: '{"city":"London"}'
            name: get_weather
          id: vj9mvwsqj
          type: function
      - content: Sunny, 22C in London
        role: tool
        tool_call_id: vj9mvwsqj
      model: meta-llama/llama-4-scout-17b-16e-instruct
      n: 1
      stream: false
      tool_choice: auto
      tools:
      - function:
          description: Get the current weather for a city.
          name: get_weather
          parameters:
            additionalProperties: false
            properties:
              city:
                type: string
            required:
            - city
            type: object
        type: function
    uri: https://api.groq.com/openai/v1/chat/completions
  response:
    headers:
      alt-svc:
      - h3=":443"; ma=86400
      cache-control:
      - private, max-age=0, no-store, no-cache, must-revalidate
      connection:
      - keep-alive
      content-length:
      - '651'
      content-type:
      - application/json
      strict-transport-security:
      - max-age=15552000
      transfer-encoding:
      - chunked
      vary:
      - Origin
    parsed_body:
      choices:
      - finish_reason: stop
        index: 0
        logprobs: null
        message:
          content: The weather in London is sunny with a temperature of 22C.
          role: assistant
      created: 1766183501
      id: chatcmpl-28c7a99e-25e4-41d1-ba7d-48fde7611a32
      model: meta-llama/llama-4-scout-17b-16e-instruct
      object: chat.completion
      service_tier: on_demand
      system_fingerprint: fp_130a0cd72d
      usage:
        completion_time: 0.034151713
        completion_tokens: 15
        prompt_time: 0.023520493
        prompt_tokens: 774
        queue_time: 0.642227919
        total_time: 0.057672206
        total_tokens: 789
      usage_breakdown: null
      x_groq:
        id: req_01kcwbtz1dfyesthdk7h8sdfdv
        seed: 1939085931
    status:
      code: 200
      message: OK
version: 1
