interactions:
- request:
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '317'
      content-type:
      - application/json
      host:
      - generativelanguage.googleapis.com
    method: POST
    parsed_body:
      contents:
      - parts:
        - text: I want to know my chinese zodiac. I am 20 years old.
        role: user
      tools:
        functionDeclarations:
        - description: ''
          name: get_chinese_zodiac
          parameters_json_schema:
            additionalProperties: false
            properties:
              age:
                type: integer
            required:
            - age
            type: object
    uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent
  response:
    headers:
      alt-svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      content-length:
      - '777'
      content-type:
      - application/json; charset=UTF-8
      server-timing:
      - gfet4t7; dur=613
      transfer-encoding:
      - chunked
      vary:
      - Origin
      - X-Origin
      - Referer
    parsed_body:
      candidates:
      - avgLogprobs: 4.6268978621810675e-06
        content:
          parts:
          - functionCall:
              args:
                age: 20
              name: get_chinese_zodiac
          role: model
        finishReason: STOP
      modelVersion: gemini-2.0-flash
      responseId: HvcgaemfJcmfz7IPtIOW-Qg
      usageMetadata:
        candidatesTokenCount: 8
        candidatesTokensDetails:
        - modality: TEXT
          tokenCount: 8
        promptTokenCount: 22
        promptTokensDetails:
        - modality: TEXT
          tokenCount: 22
        totalTokenCount: 30
    status:
      code: 200
      message: OK
- request:
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '581'
      content-type:
      - application/json
      host:
      - generativelanguage.googleapis.com
    method: POST
    parsed_body:
      contents:
      - parts:
        - text: I want to know my chinese zodiac. I am 20 years old.
        role: user
      - parts:
        - functionCall:
            args:
              age: 20
            name: get_chinese_zodiac
          thoughtSignature: context_engineering_is_the_way_to_go
        role: model
      - parts:
        - functionResponse:
            name: get_chinese_zodiac
            response:
              return_value: Dragon
        role: user
      tools:
        functionDeclarations:
        - description: ''
          name: get_chinese_zodiac
          parameters_json_schema:
            additionalProperties: false
            properties:
              age:
                type: integer
            required:
            - age
            type: object
    uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent
  response:
    headers:
      alt-svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      content-length:
      - '679'
      content-type:
      - application/json; charset=UTF-8
      server-timing:
      - gfet4t7; dur=339
      transfer-encoding:
      - chunked
      vary:
      - Origin
      - X-Origin
      - Referer
    parsed_body:
      candidates:
      - avgLogprobs: -1.7258870814527783e-05
        content:
          parts:
          - text: |
              Your Chinese zodiac is Dragon.
          role: model
        finishReason: STOP
      modelVersion: gemini-2.0-flash
      responseId: H_cgaYSjBuaEz7IPu7HpoAc
      usageMetadata:
        candidatesTokenCount: 7
        candidatesTokensDetails:
        - modality: TEXT
          tokenCount: 7
        promptTokenCount: 40
        promptTokensDetails:
        - modality: TEXT
          tokenCount: 40
        totalTokenCount: 47
    status:
      code: 200
      message: OK
- request:
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '317'
      content-type:
      - application/json
      host:
      - generativelanguage.googleapis.com
    method: POST
    parsed_body:
      contents:
      - parts:
        - text: I want to know my chinese zodiac. I am 17 years old.
        role: user
      tools:
        functionDeclarations:
        - description: ''
          name: get_chinese_zodiac
          parameters_json_schema:
            additionalProperties: false
            properties:
              age:
                type: integer
            required:
            - age
            type: object
    uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent
  response:
    headers:
      alt-svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      content-length:
      - '775'
      content-type:
      - application/json; charset=UTF-8
      server-timing:
      - gfet4t7; dur=540
      transfer-encoding:
      - chunked
      vary:
      - Origin
      - X-Origin
      - Referer
    parsed_body:
      candidates:
      - avgLogprobs: 2.42325768340379e-06
        content:
          parts:
          - functionCall:
              args:
                age: 17
              name: get_chinese_zodiac
          role: model
        finishReason: STOP
      modelVersion: gemini-2.0-flash
      responseId: H_cgabuRMOvjz7IPgrfWgAw
      usageMetadata:
        candidatesTokenCount: 8
        candidatesTokensDetails:
        - modality: TEXT
          tokenCount: 8
        promptTokenCount: 22
        promptTokensDetails:
        - modality: TEXT
          tokenCount: 22
        totalTokenCount: 30
    status:
      code: 200
      message: OK
- request:
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '797'
      content-type:
      - application/json
      host:
      - generativelanguage.googleapis.com
    method: POST
    parsed_body:
      contents:
      - parts:
        - text: I want to know my chinese zodiac. I am 17 years old.
        role: user
      - parts:
        - functionCall:
            args:
              age: 17
            name: get_chinese_zodiac
          thoughtSignature: context_engineering_is_the_way_to_go
        role: model
      - parts:
        - functionResponse:
            name: get_chinese_zodiac
            response:
              call_error: |-
                1 validation error:
                ```json
                [
                  {
                    "type": "greater_than",
                    "loc": [
                      "age"
                    ],
                    "msg": "Input should be greater than 18",
                    "input": 17
                  }
                ]
                ```

                Fix the errors and try again.
        role: user
      tools:
        functionDeclarations:
        - description: ''
          name: get_chinese_zodiac
          parameters_json_schema:
            additionalProperties: false
            properties:
              age:
                type: integer
            required:
            - age
            type: object
    uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent
  response:
    headers:
      alt-svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      content-length:
      - '778'
      content-type:
      - application/json; charset=UTF-8
      server-timing:
      - gfet4t7; dur=662
      transfer-encoding:
      - chunked
      vary:
      - Origin
      - X-Origin
      - Referer
    parsed_body:
      candidates:
      - avgLogprobs: -0.11466393163127284
        content:
          parts:
          - text: I am sorry, I cannot provide you with your Chinese zodiac sign because you are not old enough. You must
              be at least 18 years old.
          role: model
        finishReason: STOP
      modelVersion: gemini-2.0-flash
      responseId: IPcgab7GFJXQz7IP-uPC-Ac
      usageMetadata:
        candidatesTokenCount: 31
        candidatesTokensDetails:
        - modality: TEXT
          tokenCount: 31
        promptTokenCount: 113
        promptTokensDetails:
        - modality: TEXT
          tokenCount: 113
        totalTokenCount: 144
    status:
      code: 200
      message: OK
version: 1
