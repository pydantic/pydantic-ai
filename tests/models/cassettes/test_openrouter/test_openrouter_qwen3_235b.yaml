interactions:
- request:
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate, br, zstd
      connection:
      - keep-alive
      content-length:
      - '130'
      content-type:
      - application/json
      host:
      - openrouter.ai
    method: POST
    parsed_body:
      messages:
      - content: What is 2+2? Answer with just the number.
        role: user
      model: qwen/qwen3-235b-a22b
      stream: false
    uri: https://openrouter.ai/api/v1/chat/completions
  response:
    headers:
      access-control-allow-origin:
      - '*'
      connection:
      - keep-alive
      content-length:
      - '3115'
      content-type:
      - application/json
      permissions-policy:
      - payment=(self "https://checkout.stripe.com" "https://connect-js.stripe.com" "https://js.stripe.com" "https://*.js.stripe.com"
        "https://hooks.stripe.com")
      referrer-policy:
      - no-referrer, strict-origin-when-cross-origin
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
    parsed_body:
      choices:
      - finish_reason: stop
        index: 0
        logprobs: null
        message:
          content: '4'
          reasoning: |2

            Okay, so the user asked, "What is 2+2? Answer with just the number." Let me think. First, this seems like a very straightforward question. Everyone knows that 2 plus 2 equals 4. But maybe there's a catch here? Sometimes people ask simple questions to test if you're a bot or something.

            Wait, the user specified to answer with just the number. So they don't want any explanation, just the number 4. Let me make sure there's no trickery involved. For example, in base 3, 2+2 would be 11, but that's probably overcomplicating things. The question is in English, and unless stated otherwise, we assume base 10. So 2 + 2 is definitely 4. Also, the user might be checking if I can follow instructions, so I should just answer with 4. No need to add anything else.

            But wait, why would someone ask such a simple question? Maybe they're testing the AI's ability to recognize when not to elaborate. The instruction says to answer with just the number, so I should stick to that. Let me confirm once more: 2 plus 2 equals 4. Yep, that's correct. Alright, I'll just put 4 as the answer.
          reasoning_details:
          - format: null
            index: 0
            text: |2

              Okay, so the user asked, "What is 2+2? Answer with just the number." Let me think. First, this seems like a very straightforward question. Everyone knows that 2 plus 2 equals 4. But maybe there's a catch here? Sometimes people ask simple questions to test if you're a bot or something.

              Wait, the user specified to answer with just the number. So they don't want any explanation, just the number 4. Let me make sure there's no trickery involved. For example, in base 3, 2+2 would be 11, but that's probably overcomplicating things. The question is in English, and unless stated otherwise, we assume base 10. So 2 + 2 is definitely 4. Also, the user might be checking if I can follow instructions, so I should just answer with 4. No need to add anything else.

              But wait, why would someone ask such a simple question? Maybe they're testing the AI's ability to recognize when not to elaborate. The instruction says to answer with just the number, so I should stick to that. Let me confirm once more: 2 plus 2 equals 4. Yep, that's correct. Alright, I'll just put 4 as the answer.
            type: reasoning.text
          refusal: null
          role: assistant
        native_finish_reason: stop
      created: 1769543800
      id: gen-1769543800-EFyCVCAeRcYVWt5LhQOH
      model: qwen/qwen3-235b-a22b
      object: chat.completion
      provider: Fireworks
      usage:
        completion_tokens: 275
        completion_tokens_details:
          audio_tokens: 0
          reasoning_tokens: 274
        cost: 0.00024651
        cost_details:
          upstream_inference_completions_cost: 0.000242
          upstream_inference_cost: 0.00024651
          upstream_inference_prompt_cost: 4.51e-06
        is_byok: false
        prompt_tokens: 22
        prompt_tokens_details:
          audio_tokens: 0
          cached_tokens: 3
        total_tokens: 297
    status:
      code: 200
      message: OK
version: 1
