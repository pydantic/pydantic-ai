interactions:
  - request:
      body: grant_type=refresh_token&client_id=scrubbed&client_secret=scrubbed&refresh_token=scrubbed
      headers:
        accept:
          - "*/*"
        accept-encoding:
          - gzip, deflate
        connection:
          - keep-alive
        content-length:
          - "268"
        content-type:
          - application/x-www-form-urlencoded
      method: POST
      uri: https://oauth2.googleapis.com/token
    response:
      headers:
        alt-svc:
          - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
        cache-control:
          - no-cache, no-store, max-age=0, must-revalidate
        content-length:
          - "1419"
        content-type:
          - application/json; charset=utf-8
        expires:
          - Mon, 01 Jan 1990 00:00:00 GMT
        pragma:
          - no-cache
        transfer-encoding:
          - chunked
        vary:
          - Origin
          - X-Origin
          - Referer
      parsed_body:
        access_token: scrubbed
        expires_in: 3599
        id_token: scrubbed
        scope: https://www.googleapis.com/auth/cloud-platform https://www.googleapis.com/auth/userinfo.email openid https://www.googleapis.com/auth/sqlservice.login
        token_type: Bearer
      status:
        code: 200
        message: OK
  - request:
      headers:
        accept:
          - "*/*"
        accept-encoding:
          - gzip, deflate
        connection:
          - keep-alive
        content-length:
          - "249"
        content-type:
          - application/json
        host:
          - aiplatform.googleapis.com
      method: POST
      parsed_body:
        contents:
          - parts:
              - text: What is the main content of this URL?
              - fileData:
                  file_uri: gs://pydantic-ai-dev/Gemini_1_5_Pro_Technical_Report_Arxiv_1805.pdf
                  mime_type: application/pdf
            role: user
        generationConfig: {}
      uri: https://aiplatform.googleapis.com/v1beta1/projects/pydantic-ai/locations/global/publishers/google/models/gemini-2.0-flash:generateContent
    response:
      headers:
        alt-svc:
          - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
        content-length:
          - "1837"
        content-type:
          - application/json; charset=UTF-8
        transfer-encoding:
          - chunked
        vary:
          - Origin
          - X-Origin
          - Referer
      parsed_body:
        candidates:
          - avgLogprobs: -0.4750063268149771
            content:
              parts:
                - text:
                    "The URL leads to a research paper titled \"Gemini 1.5: Unlocking multimodal understanding across millions
                    of tokens of context\".  \n\nThe paper introduces Gemini 1.5 Pro, a new model in the Gemini family. It's described
                    as a highly compute-efficient multimodal mixture-of-experts model.  A key feature is its ability to recall and
                    reason over fine-grained information from millions of tokens of context, including long documents and hours
                    of video and audio.  The paper presents experimental results showcasing the model's capabilities on long-context
                    retrieval tasks, QA, ASR, and its performance compared to Gemini 1.0 models. It covers the model's architecture,
                    training data, and evaluations on both synthetic and real-world tasks.  A notable highlight is its ability to
                    learn to translate from English to Kalamang, a low-resource language, from just a grammar manual and dictionary
                    provided in context.  The paper also discusses responsible deployment considerations, including impact assessments
                    and mitigation efforts.\n"
              role: model
            finishReason: STOP
        createTime: "2025-05-31T21:34:43.658150Z"
        modelVersion: gemini-2.0-flash
        responseId: 83U7aOaVKNO8nvgPkuvc0QY
        usageMetadata:
          candidatesTokenCount: 205
          candidatesTokensDetails:
            - modality: TEXT
              tokenCount: 205
          promptTokenCount: 19875
          promptTokensDetails:
            - modality: TEXT
              tokenCount: 9
            - modality: DOCUMENT
              tokenCount: 19866
          totalTokenCount: 20080
          trafficType: ON_DEMAND
      status:
        code: 200
        message: OK
version: 1
