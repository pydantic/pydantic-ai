interactions:
- request:
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate, br
      connection:
      - keep-alive
      content-length:
      - '611'
      content-type:
      - application/json
      host:
      - generativelanguage.googleapis.com
    method: POST
    parsed_body:
      contents:
      - parts:
        - text: run bar for me please
        role: user
      generationConfig:
        responseModalities:
        - TEXT
      toolConfig:
        functionCallingConfig:
          allowedFunctionNames:
          - bar
          - final_result
          mode: ANY
      tools:
      - functionDeclarations:
        - description: ''
          name: bar
          parameters_json_schema:
            additionalProperties: false
            properties: {}
            type: object
        - description: The final response which ends this conversation
          name: final_result
          parameters_json_schema:
            properties:
              bar:
                type: string
            required:
            - bar
            type: object
    uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent
  response:
    headers:
      alt-svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      content-length:
      - '721'
      content-type:
      - application/json; charset=UTF-8
      server-timing:
      - gfet4t7; dur=1092
      transfer-encoding:
      - chunked
      vary:
      - Origin
      - X-Origin
      - Referer
    parsed_body:
      candidates:
      - avgLogprobs: 2.911267802119255e-05
        content:
          parts:
          - functionCall:
              args: {}
              name: bar
          role: model
        finishReason: STOP
      modelVersion: gemini-2.0-flash
      responseId: 21R8aeD7KP7aqtsP_tH-uAI
      usageMetadata:
        candidatesTokenCount: 1
        candidatesTokensDetails:
        - modality: TEXT
          tokenCount: 1
        promptTokenCount: 16
        promptTokensDetails:
        - modality: TEXT
          tokenCount: 16
        totalTokenCount: 17
    status:
      code: 200
      message: OK
- request:
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate, br
      connection:
      - keep-alive
      content-length:
      - '961'
      content-type:
      - application/json
      host:
      - generativelanguage.googleapis.com
    method: POST
    parsed_body:
      contents:
      - parts:
        - text: run bar for me please
        role: user
      - parts:
        - functionCall:
            args: {}
            id: pyd_ai_903796605e794c37a7e179313d87d7ae
            name: bar
          thoughtSignature: c2tpcF90aG91Z2h0X3NpZ25hdHVyZV92YWxpZGF0b3I=
        role: model
      - parts:
        - functionResponse:
            id: pyd_ai_903796605e794c37a7e179313d87d7ae
            name: bar
            response:
              return_value: hello
        role: user
      generationConfig:
        responseModalities:
        - TEXT
      toolConfig:
        functionCallingConfig:
          allowedFunctionNames:
          - bar
          - final_result
          mode: ANY
      tools:
      - functionDeclarations:
        - description: ''
          name: bar
          parameters_json_schema:
            additionalProperties: false
            properties: {}
            type: object
        - description: The final response which ends this conversation
          name: final_result
          parameters_json_schema:
            properties:
              bar:
                type: string
            required:
            - bar
            type: object
    uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent
  response:
    headers:
      alt-svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      content-length:
      - '775'
      content-type:
      - application/json; charset=UTF-8
      server-timing:
      - gfet4t7; dur=1112
      transfer-encoding:
      - chunked
      vary:
      - Origin
      - X-Origin
      - Referer
    parsed_body:
      candidates:
      - avgLogprobs: -0.02294951379299164
        content:
          parts:
          - functionCall:
              args:
                bar: hello
              name: final_result
          role: model
        finishReason: STOP
      modelVersion: gemini-2.0-flash
      responseId: 3FR8afu2OLGwqtsPqv7A4AI
      usageMetadata:
        candidatesTokenCount: 5
        candidatesTokensDetails:
        - modality: TEXT
          tokenCount: 5
        promptTokenCount: 22
        promptTokensDetails:
        - modality: TEXT
          tokenCount: 22
        totalTokenCount: 27
    status:
      code: 200
      message: OK
version: 1
