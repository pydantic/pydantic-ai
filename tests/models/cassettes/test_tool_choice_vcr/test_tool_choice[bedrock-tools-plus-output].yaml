interactions:
- request:
    body: '{"messages": [{"role": "user", "content": [{"text": "Get weather for Paris and summarize"}]}], "system": [], "inferenceConfig":
      {}, "toolConfig": {"tools": [{"toolSpec": {"name": "get_weather", "inputSchema": {"json": {"additionalProperties": false,
      "properties": {"city": {"type": "string"}}, "required": ["city"], "type": "object"}}, "description": "Get the current
      weather for a city."}}, {"toolSpec": {"name": "final_result", "inputSchema": {"json": {"properties": {"city": {"type":
      "string"}, "summary": {"type": "string"}}, "required": ["city", "summary"], "title": "CityInfo", "type": "object"}},
      "description": "Structured output model for city information."}}], "toolChoice": {"any": {}}}}'
    headers:
      amz-sdk-invocation-id:
      - !!binary |
        OTU2MmU0MWUtMzdiZi00ZDg1LWI1MmItMzAxNTA3ZWE5NTli
      amz-sdk-request:
      - !!binary |
        YXR0ZW1wdD0x
      content-length:
      - '698'
      content-type:
      - !!binary |
        YXBwbGljYXRpb24vanNvbg==
    method: POST
    uri: https://bedrock-runtime.us-east-2.amazonaws.com/model/us.anthropic.claude-sonnet-4-5-20250929-v1%3A0/converse
  response:
    headers:
      connection:
      - keep-alive
      content-length:
      - '426'
      content-type:
      - application/json
    parsed_body:
      metrics:
        latencyMs: 1632
      output:
        message:
          content:
          - toolUse:
              input:
                city: Paris
              name: get_weather
              toolUseId: tooluse_J_MN-ZX5TWSFCbXDx54HiA
              type: tool_use
          role: assistant
      stopReason: tool_use
      usage:
        cacheReadInputTokenCount: 0
        cacheReadInputTokens: 0
        cacheWriteInputTokenCount: 0
        cacheWriteInputTokens: 0
        inputTokens: 740
        outputTokens: 38
        serverToolUsage: {}
        totalTokens: 778
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": [{"text": "Get weather for Paris and summarize"}]}, {"role": "assistant",
      "content": [{"toolUse": {"toolUseId": "tooluse_J_MN-ZX5TWSFCbXDx54HiA", "name": "get_weather", "input": {"city": "Paris"}}}]},
      {"role": "user", "content": [{"toolResult": {"toolUseId": "tooluse_J_MN-ZX5TWSFCbXDx54HiA", "content": [{"text": "Sunny,
      22C in Paris"}], "status": "success"}}]}], "system": [], "inferenceConfig": {}, "toolConfig": {"tools": [{"toolSpec":
      {"name": "get_weather", "inputSchema": {"json": {"additionalProperties": false, "properties": {"city": {"type": "string"}},
      "required": ["city"], "type": "object"}}, "description": "Get the current weather for a city."}}, {"toolSpec": {"name":
      "final_result", "inputSchema": {"json": {"properties": {"city": {"type": "string"}, "summary": {"type": "string"}},
      "required": ["city", "summary"], "title": "CityInfo", "type": "object"}}, "description": "Structured output model for
      city information."}}], "toolChoice": {"any": {}}}}'
    headers:
      amz-sdk-invocation-id:
      - !!binary |
        ODczZDY1NTgtZmU3MC00MTdlLWEzN2QtZDE1OWFlN2U0MDky
      amz-sdk-request:
      - !!binary |
        YXR0ZW1wdD0x
      content-length:
      - '1010'
      content-type:
      - !!binary |
        YXBwbGljYXRpb24vanNvbg==
    method: POST
    uri: https://bedrock-runtime.us-east-2.amazonaws.com/model/us.anthropic.claude-sonnet-4-5-20250929-v1%3A0/converse
  response:
    headers:
      connection:
      - keep-alive
      content-length:
      - '573'
      content-type:
      - application/json
    parsed_body:
      metrics:
        latencyMs: 2037
      output:
        message:
          content:
          - toolUse:
              input:
                city: Paris
                summary: The weather in Paris is currently sunny with a pleasant temperature of 22°C (72°F), perfect for outdoor
                  activities and sightseeing.
              name: final_result
              toolUseId: tooluse_Od5YeumDToSO1IdWNRqJPg
              type: tool_use
          role: assistant
      stopReason: tool_use
      usage:
        cacheReadInputTokenCount: 0
        cacheReadInputTokens: 0
        cacheWriteInputTokenCount: 0
        cacheWriteInputTokens: 0
        inputTokens: 813
        outputTokens: 84
        serverToolUsage: {}
        totalTokens: 897
    status:
      code: 200
      message: OK
version: 1
