interactions:
- request:
    body: null
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate, br
      connection:
      - keep-alive
    method: GET
    uri: https://huggingface.co/api/models/meta-llama/Llama-4-Scout-17B-16E-Instruct?expand=inferenceProviderMapping
  response:
    headers:
      access-control-allow-origin:
      - https://huggingface.co
      access-control-expose-headers:
      - X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash
      access-control-max-age:
      - '86400'
      connection:
      - keep-alive
      content-length:
      - '904'
      content-type:
      - application/json; charset=utf-8
      cross-origin-opener-policy:
      - same-origin
      etag:
      - W/"388-myb6zbS3leJ0g7Gjjeu5p4iBNkw"
      ratelimit:
      - '"api";r=999;t=238'
      ratelimit-policy:
      - '"fixed window";"api";q=1000;w=300'
      referrer-policy:
      - strict-origin-when-cross-origin
      vary:
      - Origin
    parsed_body:
      _id: 67ed3cd9290a7f9d3301f9c1
      id: meta-llama/Llama-4-Scout-17B-16E-Instruct
      inferenceProviderMapping:
        fireworks-ai:
          isModelAuthor: false
          providerId: accounts/fireworks/models/llama4-scout-instruct-basic
          status: error
          task: conversational
        groq:
          isModelAuthor: false
          providerId: meta-llama/llama-4-scout-17b-16e-instruct
          status: live
          task: conversational
        novita:
          isModelAuthor: false
          providerId: meta-llama/llama-4-scout-17b-16e-instruct
          status: live
          task: conversational
        nscale:
          isModelAuthor: false
          providerId: meta-llama/Llama-4-Scout-17B-16E-Instruct
          status: live
          task: conversational
        sambanova:
          isModelAuthor: false
          providerId: Llama-4-Scout-17B-16E-Instruct
          status: error
          task: conversational
        together:
          isModelAuthor: false
          providerId: meta-llama/Llama-4-Scout-17B-16E-Instruct
          status: live
          task: conversational
    status:
      code: 200
      message: OK
- request:
    body:
      messages:
      - content: What's the weather in Paris?
        role: user
      model: meta-llama/Llama-4-Scout-17B-16E-Instruct
      stream: false
      tool_choice: auto
      tools:
      - function:
          description: Get the current weather for a city.
          name: get_weather
          parameters:
            additionalProperties: false
            properties:
              city:
                type: string
            required:
            - city
            type: object
        type: function
    headers:
      content-type:
      - application/json
    method: POST
    uri: https://router.huggingface.co/together/v1/chat/completions
  response:
    headers:
      access-control-allow-origin:
      - '*'
      access-control-expose-headers:
      - X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash
      connection:
      - keep-alive
      content-type:
      - application/json; charset=utf-8
      cross-origin-opener-policy:
      - same-origin
      etag:
      - W/"353-aiBOOXqjsrvH2utEBoTbEl4Ja6w"
      referrer-policy:
      - strict-origin-when-cross-origin
      retry-after:
      - '2'
      strict-transport-security:
      - max-age=15552000; includeSubDomains
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
    parsed_body:
      choices:
      - finish_reason: tool_calls
        index: 0
        logprobs: null
        message:
          content: ''
          reasoning: null
          role: assistant
          tool_calls:
          - function:
              arguments: '{"city": "Paris"}'
              name: get_weather
            id: call_5173c0845b0847089b22e920
            index: 0
            type: function
        seed: null
      created: 1767661737
      id: oS9DT8V-z1gNr-9b9753c20c29d698
      metadata:
        weight_version: default
      model: meta-llama/Llama-4-Scout-17B-16E-Instruct
      object: chat.completion
      prompt: []
      usage:
        completion_tokens: 7
        prompt_tokens: 617
        total_tokens: 624
    status:
      code: 200
      message: OK
- request:
    body:
      messages:
      - content: What's the weather in Paris?
        role: user
      - role: assistant
        tool_calls:
        - function:
            name: get_weather
          id: call_5173c0845b0847089b22e920
          type: function
      - content: Sunny, 22C in Paris
        role: tool
        tool_call_id: call_5173c0845b0847089b22e920
      model: meta-llama/Llama-4-Scout-17B-16E-Instruct
      stream: false
      tool_choice: auto
      tools:
      - function:
          description: Get the current weather for a city.
          name: get_weather
          parameters:
            additionalProperties: false
            properties:
              city:
                type: string
            required:
            - city
            type: object
        type: function
    headers:
      content-type:
      - application/json
    method: POST
    uri: https://router.huggingface.co/together/v1/chat/completions
  response:
    headers:
      access-control-allow-origin:
      - '*'
      access-control-expose-headers:
      - X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash
      connection:
      - keep-alive
      content-length:
      - '166'
      content-type:
      - application/json; charset=utf-8
      cross-origin-opener-policy:
      - same-origin
      etag:
      - W/"a6-u9XYEmV/BHKBKNo5uK1nuL6wcrY"
      referrer-policy:
      - strict-origin-when-cross-origin
      retry-after:
      - '1'
      strict-transport-security:
      - max-age=15552000; includeSubDomains
      vary:
      - Accept-Encoding
    parsed_body:
      error:
        code: null
        message: Internal server error
        param: null
        type: server_error
      id: oS9DTK6-z1gNr-9b9753c67e3c20b4
    status:
      code: 500
      message: Internal Server Error
version: 1
