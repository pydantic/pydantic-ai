interactions:
- request:
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate, br, zstd
      connection:
      - keep-alive
      content-length:
      - '320'
      content-type:
      - application/json
      host:
      - api.openai.com
    method: POST
    parsed_body:
      messages:
      - content: Call the get_file tool to get a video and describe what you see.
        role: user
      model: gpt-4.1-mini
      stream: false
      tool_choice: auto
      tools:
      - function:
          description: ''
          name: get_file
          parameters:
            additionalProperties: false
            properties: {}
            type: object
        type: function
    uri: https://api.openai.com/v1/chat/completions
  response:
    headers:
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      connection:
      - keep-alive
      content-length:
      - '1064'
      content-type:
      - application/json
      openai-organization:
      - user-grnwlxd1653lxdzp921aoihz
      openai-processing-ms:
      - '471'
      openai-project:
      - proj_FYsIItHHgnSPdHBVMzhNBWGa
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=31536000; includeSubDomains; preload
      transfer-encoding:
      - chunked
    parsed_body:
      choices:
      - finish_reason: tool_calls
        index: 0
        logprobs: null
        message:
          annotations: []
          content: null
          refusal: null
          role: assistant
          tool_calls:
          - function:
              arguments: '{}'
              name: get_file
            id: call_RFVGNlxISPS9LC8RUICWekr7
            type: function
      created: 1769565244
      id: chatcmpl-D2p2qc32lwweF421H4t4gCjshb1k4
      model: gpt-4.1-mini-2025-04-14
      object: chat.completion
      service_tier: default
      system_fingerprint: fp_376a7ccef1
      usage:
        completion_tokens: 10
        completion_tokens_details:
          accepted_prediction_tokens: 0
          audio_tokens: 0
          reasoning_tokens: 0
          rejected_prediction_tokens: 0
        prompt_tokens: 46
        prompt_tokens_details:
          audio_tokens: 0
          cached_tokens: 0
        total_tokens: 56
    status:
      code: 200
      message: OK
version: 1
