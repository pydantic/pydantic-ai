interactions:
- request:
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '80'
      content-type:
      - application/json
      host:
      - api.openai.com
    method: POST
    parsed_body:
      messages:
      - content: Hello
        role: user
      model: gpt-4o
      stream: false
    uri: https://api.openai.com/v1/chat/completions
  response:
    headers:
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      connection:
      - keep-alive
      content-length:
      - '834'
      content-type:
      - application/json
      openai-organization:
      - user-hmtx7ob9xfpodrsdmshpnklm
      openai-processing-ms:
      - '251'
      openai-project:
      - proj_98JsR0JYQV1Ovk2AT0cljXCL
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=31536000; includeSubDomains; preload
      transfer-encoding:
      - chunked
    parsed_body:
      choices:
      - finish_reason: stop
        index: 0
        logprobs: null
        message:
          annotations: []
          content: Hello! How can I assist you today?
          refusal: null
          role: assistant
      created: 1765482647
      id: chatcmpl-ClgyV6EOmHq1TJode5efdWKWr6N7i
      model: gpt-4o-2024-08-06
      object: chat.completion
      service_tier: default
      system_fingerprint: fp_83554c687e
      usage:
        completion_tokens: 9
        completion_tokens_details:
          accepted_prediction_tokens: 0
          audio_tokens: 0
          reasoning_tokens: 0
          rejected_prediction_tokens: 0
        prompt_tokens: 8
        prompt_tokens_details:
          audio_tokens: 0
          cached_tokens: 0
        total_tokens: 17
    status:
      code: 200
      message: OK
- request:
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '191'
      content-type:
      - application/json
      cookie:
      - __cf_bm=ZHIxcqU5XRY5rncqK1YhUUnHuc38vD9dY269NprfYEY-1765482647-1.0.1.1-4qRp5ROrSeOWa1emaDiefiQmvPqqchMpeapBVqymsg7rEBmRTKjNsVkj9JIz5VM_6PXWuRLVQsmaIpvBkJAAVo4n8pBqXJJnDPGVC4Oqu6w;
        _cfuvid=Px3UzGOdCJlFZr7b1Y9JxFXa_04NGfL0QoY2yLQzPf8-1765482647950-0.0.1.1-604800000
      host:
      - api.openai.com
    method: POST
    parsed_body:
      messages:
      - content: Hello
        role: user
      - content: Hello! How can I assist you today?
        role: assistant
      - content: Tell me a joke
        role: user
      model: gpt-4o
      stream: false
    uri: https://api.openai.com/v1/chat/completions
  response:
    headers:
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      connection:
      - keep-alive
      content-length:
      - '897'
      content-type:
      - application/json
      openai-organization:
      - user-hmtx7ob9xfpodrsdmshpnklm
      openai-processing-ms:
      - '689'
      openai-project:
      - proj_98JsR0JYQV1Ovk2AT0cljXCL
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=31536000; includeSubDomains; preload
      transfer-encoding:
      - chunked
    parsed_body:
      choices:
      - finish_reason: stop
        index: 0
        logprobs: null
        message:
          annotations: []
          content: |-
            Sure, here's one for you:

            Why don't skeletons fight each other?

            They don't have the guts.
          refusal: null
          role: assistant
      created: 1765482649
      id: chatcmpl-ClgyXQic3GI47e7RYxxwKWa9p7ki3
      model: gpt-4o-2024-08-06
      object: chat.completion
      service_tier: default
      system_fingerprint: fp_83554c687e
      usage:
        completion_tokens: 21
        completion_tokens_details:
          accepted_prediction_tokens: 0
          audio_tokens: 0
          reasoning_tokens: 0
          rejected_prediction_tokens: 0
        prompt_tokens: 29
        prompt_tokens_details:
          audio_tokens: 0
          cached_tokens: 0
        total_tokens: 50
    status:
      code: 200
      message: OK
version: 1
