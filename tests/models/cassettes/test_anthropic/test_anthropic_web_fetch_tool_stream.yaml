interactions:
- request:
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate, br, zstd
      connection:
      - keep-alive
      content-length:
      - '466'
      content-type:
      - application/json
      host:
      - api.anthropic.com
    method: POST
    parsed_body:
      max_tokens: 4096
      messages:
      - content:
        - text: What is the first sentence on the page https://ai.pydantic.dev? Reply with only the sentence.
          type: text
        role: user
      model: claude-sonnet-4-0
      stream: true
      thinking:
        budget_tokens: 3000
        type: enabled
      tool_choice:
        type: auto
      tools:
      - allowed_domains: null
        blocked_domains: null
        citations: null
        max_content_tokens: null
        max_uses: null
        name: web_fetch
        type: web_fetch_20250910
    uri: https://api.anthropic.com/v1/messages?beta=true
  response:
    body:
      string: "event: message_start\ndata: {\"type\":\"message_start\",\"message\":{\"model\":\"claude-sonnet-4-20250514\",\"id\":\"msg_01Ajb4zXf1QqaXK6UGXgusUH\",\"type\":\"message\",\"role\":\"assistant\",\"content\":[],\"stop_reason\":null,\"stop_sequence\":null,\"usage\":{\"input_tokens\":899,\"cache_creation_input_tokens\":0,\"cache_read_input_tokens\":0,\"cache_creation\":{\"ephemeral_5m_input_tokens\":0,\"ephemeral_1h_input_tokens\":0},\"output_tokens\":5,\"service_tier\":\"standard\"}}
        \          }\n\nevent: content_block_start\ndata: {\"type\":\"content_block_start\",\"index\":0,\"content_block\":{\"type\":\"thinking\",\"thinking\":\"\",\"signature\":\"\"}
        \              }\n\nevent: ping\ndata: {\"type\": \"ping\"}\n\nevent: content_block_delta\ndata: {\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"thinking_delta\",\"thinking\":\"The
        user is asking me\"}             }\n\nevent: content_block_delta\ndata: {\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"thinking_delta\",\"thinking\":\"
        to fetch\"}        }\n\nevent: content_block_delta\ndata: {\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"thinking_delta\",\"thinking\":\"
        the content\"}          }\n\nevent: content_block_delta\ndata: {\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"thinking_delta\",\"thinking\":\"
        from\"}            }\n\nevent: content_block_delta\ndata: {\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"thinking_delta\",\"thinking\":\"
        https\"} }\n\nevent: content_block_delta\ndata: {\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"thinking_delta\",\"thinking\":\"://ai.pydantic.dev\"}}\n\nevent:
        content_block_delta\ndata: {\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"thinking_delta\",\"thinking\":\"
        and provide\"} }\n\nevent: content_block_delta\ndata: {\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"thinking_delta\",\"thinking\":\"
        only\"}       }\n\nevent: content_block_delta\ndata: {\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"thinking_delta\",\"thinking\":\"
        the first sentence from\"}    }\n\nevent: content_block_delta\ndata: {\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"thinking_delta\",\"thinking\":\"
        that page.\"}      }\n\nevent: content_block_delta\ndata: {\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"thinking_delta\",\"thinking\":\"
        I\"}             }\n\nevent: content_block_delta\ndata: {\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"thinking_delta\",\"thinking\":\"
        need to use the web_fetch tool\"}}\n\nevent: content_block_delta\ndata: {\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"thinking_delta\",\"thinking\":\"
        to\"}   }\n\nevent: content_block_delta\ndata: {\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"thinking_delta\",\"thinking\":\"
        get the content from\"}               }\n\nevent: content_block_delta\ndata: {\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"thinking_delta\",\"thinking\":\"
        this\"}             }\n\nevent: content_block_delta\ndata: {\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"thinking_delta\",\"thinking\":\"
        URL,\"}             }\n\nevent: content_block_delta\ndata: {\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"thinking_delta\",\"thinking\":\"
        then\"}  }\n\nevent: content_block_delta\ndata: {\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"thinking_delta\",\"thinking\":\"
        identify\"}              }\n\nevent: content_block_delta\ndata: {\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"thinking_delta\",\"thinking\":\"
        and\"}              }\n\nevent: content_block_delta\ndata: {\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"thinking_delta\",\"thinking\":\"
        return just the first sentence.\"}        }\n\nevent: content_block_delta\ndata: {\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"thinking_delta\",\"thinking\":\"\"}
        \       }\n\nevent: content_block_delta\ndata: {\"type\":\"content_block_delta\",\"index\":0,\"delta\":{\"type\":\"signature_delta\",\"signature\":\"EpkDCkYICxgCKkCQfOq+gEPQZDPE7TCjy3DoVNBdYNE+46NSvmhdtm/yrdYjpMI8kMy2fqKrvc9kpsJsRCdE+MZMaavEFdZXFS7NEgxOkF+GhZ3LPui+laQaDHt2QT9QfXFB6iVkkiIwk8cdAciJ0IgFsxs+HggQlcYLFm4V/9E4JjAaF6eLXKgNH1aOrixXepyh+LhZ5LPFKoACiMJWMj3OLKvmuHCp5U7S8TK3TPYzCyMAUtA2gadh1w3AL5YhoWPZx1lQBmZ3h1L6NqNmIDptKA5FmWhX4FRYAQwPnKpAlo/OYbm9H2vgUhRN6NmEai1VUpBigpExszfyjiW7cwnw3N1dhHv0QqsDT7Hc0kVAoF7Gd4zCz2/PbFYjgU/Lt4wBdzkgP//Z0Y2Rdvz1duTjL2XSLJdHkasTHWMkDRLxwQhkc3SXE971tZtrFs/uRuSbNhETPHRMiir2JgT7O3snG7I+GISLTClODFJvC3o2uye2UGWqAiIZ71JK0qGo5fqA++H39K95G1tljzPXFunq5+WpPZwcNfo0hRgB\"}
        \             }\n\nevent: content_block_stop\ndata: {\"type\":\"content_block_stop\",\"index\":0   }\n\nevent: content_block_start\ndata:
        {\"type\":\"content_block_start\",\"index\":1,\"content_block\":{\"type\":\"server_tool_use\",\"id\":\"srvtoolu_01E4Qp3Q56a2PCnd22MK4JJB\",\"name\":\"web_fetch\",\"input\":{}}
        \    }\n\nevent: content_block_delta\ndata: {\"type\":\"content_block_delta\",\"index\":1,\"delta\":{\"type\":\"input_json_delta\",\"partial_json\":\"\"}
        \          }\n\nevent: content_block_delta\ndata: {\"type\":\"content_block_delta\",\"index\":1,\"delta\":{\"type\":\"input_json_delta\",\"partial_json\":\"{\\\"u\"}
        \  }\n\nevent: content_block_delta\ndata: {\"type\":\"content_block_delta\",\"index\":1,\"delta\":{\"type\":\"input_json_delta\",\"partial_json\":\"rl\\\":
        \\\"https\"}     }\n\nevent: content_block_delta\ndata: {\"type\":\"content_block_delta\",\"index\":1,\"delta\":{\"type\":\"input_json_delta\",\"partial_json\":\"://ai.py\"}
        \  }\n\nevent: content_block_delta\ndata: {\"type\":\"content_block_delta\",\"index\":1,\"delta\":{\"type\":\"input_json_delta\",\"partial_json\":\"dantic\"}
        \           }\n\nevent: content_block_delta\ndata: {\"type\":\"content_block_delta\",\"index\":1,\"delta\":{\"type\":\"input_json_delta\",\"partial_json\":\".dev\\\"}\"}
        \           }\n\nevent: content_block_stop\ndata: {\"type\":\"content_block_stop\",\"index\":1 }\n\nevent: content_block_start\ndata:
        {\"type\":\"content_block_start\",\"index\":2,\"content_block\":{\"type\":\"web_fetch_tool_result\",\"tool_use_id\":\"srvtoolu_01E4Qp3Q56a2PCnd22MK4JJB\",\"content\":{\"type\":\"web_fetch_result\",\"url\":\"https://ai.pydantic.dev\",\"retrieved_at\":\"2026-01-30T00:19:27.579000+00:00\",\"content\":{\"type\":\"document\",\"source\":{\"type\":\"text\",\"media_type\":\"text/plain\",\"data\":\"Pydantic
        AI - Pydantic AI\\n\\n\\n\\n\\n\\n\\n[Skip to content](#pydantic-ai)\\n\\n**Join us at the inaugural PyAI Conf in
        San Francisco on March 10th!\\n[Learn More](https://pyai.events/?utm_source=pydantic-ai)**\\n\\n[![logo](img/logo-white.svg)](.
        \\\"Pydantic AI\\\")\\n\\n\\n\\n\\nPydantic AI\\n\\nPydantic AI\\n\\n\\n\\n\\n\\n\\n\\nType to start searching\\n\\n[pydantic/pydantic-ai](https://github.com/pydantic/pydantic-ai
        \\\"Go to repository\\\")\\n\\n[![logo](img/logo-white.svg)](. \\\"Pydantic AI\\\")\\nPydantic AI\\n\\n[pydantic/pydantic-ai](https://github.com/pydantic/pydantic-ai
        \\\"Go to repository\\\")\\n\\n* Pydantic AI\\n\\n  [Pydantic AI](.)\\n\\n\\n\\n  Table of contents\\n  + [Why use
        Pydantic AI](#why-use-pydantic-ai)\\n  + [Hello World Example](#hello-world-example)\\n  + [Tools & Dependency Injection
        Example](#tools-dependency-injection-example)\\n  + [Instrumentation with Pydantic Logfire](#instrumentation-with-pydantic-logfire)\\n
        \ + [llms.txt](#llmstxt)\\n  + [Next Steps](#next-steps)\\n* [Installation](install/)\\n* [Getting Help](help/)\\n*
        [Troubleshooting](troubleshooting/)\\n* [Pydantic AI Gateway](gateway/)\\n* Documentation\\n\\n\\n\\n\\n  Documentation\\n
        \ + Core Concepts\\n\\n\\n\\n\\n    Core Concepts\\n    - [Agents](agents/)\\n    - [Dependencies](dependencies/)\\n
        \   - [Function Tools](tools/)\\n    - [Output](output/)\\n    - [Messages and chat history](message-history/)\\n
        \   - [Direct Model Requests](direct/)\\n  + Models & Providers\\n\\n\\n\\n\\n    Models & Providers\\n    - [Overview](models/overview/)\\n
        \   - [OpenAI](models/openai/)\\n    - [Anthropic](models/anthropic/)\\n    - [Google](models/google/)\\n    - [xAI](models/xai/)\\n
        \   - [Bedrock](models/bedrock/)\\n    - [Cerebras](models/cerebras/)\\n    - [Cohere](models/cohere/)\\n    - [Groq](models/groq/)\\n
        \   - [Hugging Face](models/huggingface/)\\n    - [Mistral](models/mistral/)\\n    - [OpenRouter](models/openrouter/)\\n
        \   - [Outlines](models/outlines/)\\n  + Tools & Toolsets\\n\\n\\n\\n\\n    Tools & Toolsets\\n    - [Function Tools](tools/)\\n
        \   - [Advanced Tool Features](tools-advanced/)\\n    - [Toolsets](toolsets/)\\n    - [Deferred Tools](deferred-tools/)\\n
        \   - [Built-in Tools](builtin-tools/)\\n    - [Common Tools](common-tools/)\\n    - [Third-Party Tools](third-party-tools/)\\n
        \ + Advanced Features\\n\\n\\n\\n\\n    Advanced Features\\n    - [Image, Audio, Video & Document Input](input/)\\n
        \   - [Thinking](thinking/)\\n    - [HTTP Request Retries](retries/)\\n  + MCP\\n\\n\\n\\n\\n    MCP\\n    - [Overview](mcp/overview/)\\n
        \   - [Client](mcp/client/)\\n    - [FastMCP Client](mcp/fastmcp-client/)\\n    - [Server](mcp/server/)\\n  + [Multi-Agent
        Patterns](multi-agent-applications/)\\n  + [Web Chat UI](web/)\\n  + [Embeddings](embeddings/)\\n  + [Testing](testing/)\\n*
        Pydantic Evals\\n\\n\\n\\n\\n  Pydantic Evals\\n  + [Overview](evals/)\\n  + Getting Started\\n\\n\\n\\n\\n    Getting
        Started\\n    - [Quick Start](evals/quick-start/)\\n    - [Core Concepts](evals/core-concepts/)\\n  + Evaluators\\n\\n\\n\\n\\n
        \   Evaluators\\n    - [Overview](evals/evaluators/overview/)\\n    - [Built-in Evaluators](evals/evaluators/built-in/)\\n
        \   - [LLM Judge](evals/evaluators/llm-judge/)\\n    - [Custom Evaluators](evals/evaluators/custom/)\\n    - [Span-Based](evals/evaluators/span-based/)\\n
        \ + How-To Guides\\n\\n\\n\\n\\n    How-To Guides\\n    - [Logfire Integration](evals/how-to/logfire-integration/)\\n
        \   - [Dataset Management](evals/how-to/dataset-management/)\\n    - [Dataset Serialization](evals/how-to/dataset-serialization/)\\n
        \   - [Concurrency & Performance](evals/how-to/concurrency/)\\n    - [Retry Strategies](evals/how-to/retry-strategies/)\\n
        \   - [Metrics & Attributes](evals/how-to/metrics-attributes/)\\n  + Examples\\n\\n\\n\\n\\n    Examples\\n    - [Simple
        Validation](evals/examples/simple-validation/)\\n* Pydantic Graph\\n\\n\\n\\n\\n  Pydantic Graph\\n  + [Overview](graph/)\\n
        \ + [Beta API](graph/beta/)\\n\\n    Beta API\\n    - [Steps](graph/beta/steps/)\\n    - [Joins & Reducers](graph/beta/joins/)\\n
        \   - [Decisions](graph/beta/decisions/)\\n    - [Parallel Execution](graph/beta/parallel/)\\n* Integrations\\n\\n\\n\\n\\n
        \ Integrations\\n  + [Debugging & Monitoring with Pydantic Logfire](logfire/)\\n  + Durable Execution\\n\\n\\n\\n\\n
        \   Durable Execution\\n    - [Overview](durable_execution/overview/)\\n    - [Temporal](durable_execution/temporal/)\\n
        \   - [DBOS](durable_execution/dbos/)\\n    - [Prefect](durable_execution/prefect/)\\n  + UI Event Streams\\n\\n\\n\\n\\n
        \   UI Event Streams\\n    - [Overview](ui/overview/)\\n    - [AG-UI](ui/ag-ui/)\\n    - [Vercel AI](ui/vercel-ai/)\\n
        \ + [Agent2Agent (A2A)](a2a/)\\n* Related Packages\\n\\n\\n\\n\\n  Related Packages\\n  + [Clai](cli/)\\n* Examples\\n\\n\\n\\n\\n
        \ Examples\\n  + [Setup](examples/setup/)\\n  + Getting Started\\n\\n\\n\\n\\n    Getting Started\\n    - [Pydantic
        Model](examples/pydantic-model/)\\n    - [Weather agent](examples/weather-agent/)\\n  + Conversational Agents\\n\\n\\n\\n\\n
        \   Conversational Agents\\n    - [Chat App with FastAPI](examples/chat-app/)\\n    - [Bank support](examples/bank-support/)\\n
        \ + Data & Analytics\\n\\n\\n\\n\\n    Data & Analytics\\n    - [SQL Generation](examples/sql-gen/)\\n    - [Data
        Analyst](examples/data-analyst/)\\n    - [RAG](examples/rag/)\\n  + Streaming\\n\\n\\n\\n\\n    Streaming\\n    -
        [Stream markdown](examples/stream-markdown/)\\n    - [Stream whales](examples/stream-whales/)\\n  + Complex Workflows\\n\\n\\n\\n\\n
        \   Complex Workflows\\n    - [Flight booking](examples/flight-booking/)\\n    - [Question Graph](examples/question-graph/)\\n
        \ + Business Applications\\n\\n\\n\\n\\n    Business Applications\\n    - [Slack Lead Qualifier with Modal](examples/slack-lead-qualifier/)\\n
        \ + UI Examples\\n\\n\\n\\n\\n    UI Examples\\n    - [Agent User Interaction (AG-UI)](examples/ag-ui/)\\n* API Reference\\n\\n\\n\\n\\n
        \ API Reference\\n  + pydantic\\\\_ai\\n\\n\\n\\n\\n    pydantic\\\\_ai\\n    - [pydantic\\\\_ai.ag\\\\_ui](api/ag_ui/)\\n
        \   - [pydantic\\\\_ai.agent](api/agent/)\\n    - [pydantic\\\\_ai.builtin\\\\_tools](api/builtin_tools/)\\n    -
        [pydantic\\\\_ai.common\\\\_tools](api/common_tools/)\\n    - [pydantic\\\\_ai.direct](api/direct/)\\n    - [pydantic\\\\_ai.durable\\\\_exec](api/durable_exec/)\\n
        \   - [pydantic\\\\_ai.embeddings](api/embeddings/)\\n    - [pydantic\\\\_ai.exceptions](api/exceptions/)\\n    -
        [pydantic\\\\_ai.ext](api/ext/)\\n    - [pydantic\\\\_ai.format\\\\_prompt](api/format_prompt/)\\n    - [pydantic\\\\_ai.mcp](api/mcp/)\\n
        \   - [pydantic\\\\_ai.messages](api/messages/)\\n    - [pydantic\\\\_ai.models.anthropic](api/models/anthropic/)\\n
        \   - [pydantic\\\\_ai.models](api/models/base/)\\n    - [pydantic\\\\_ai.models.bedrock](api/models/bedrock/)\\n
        \   - [pydantic\\\\_ai.models.cerebras](api/models/cerebras/)\\n    - [pydantic\\\\_ai.models.cohere](api/models/cohere/)\\n
        \   - [pydantic\\\\_ai.models.fallback](api/models/fallback/)\\n    - [pydantic\\\\_ai.models.function](api/models/function/)\\n
        \   - [pydantic\\\\_ai.models.google](api/models/google/)\\n    - [pydantic\\\\_ai.models.xai](api/models/xai/)\\n
        \   - [pydantic\\\\_ai.models.groq](api/models/groq/)\\n    - [pydantic\\\\_ai.models.huggingface](api/models/huggingface/)\\n
        \   - [pydantic\\\\_ai.models.instrumented](api/models/instrumented/)\\n    - [pydantic\\\\_ai.models.mcp\\\\_sampling](api/models/mcp-sampling/)\\n
        \   - [pydantic\\\\_ai.models.mistral](api/models/mistral/)\\n    - [pydantic\\\\_ai.models.openai](api/models/openai/)\\n
        \   - [pydantic\\\\_ai.models.openrouter](api/models/openrouter/)\\n    - [pydantic\\\\_ai.models.outlines](api/models/outlines/)\\n
        \   - [pydantic\\\\_ai.models.test](api/models/test/)\\n    - [pydantic\\\\_ai.models.wrapper](api/models/wrapper/)\\n
        \   - [pydantic\\\\_ai.output](api/output/)\\n    - [pydantic\\\\_ai.profiles](api/profiles/)\\n    - [pydantic\\\\_ai.providers](api/providers/)\\n
        \   - [pydantic\\\\_ai.result](api/result/)\\n    - [pydantic\\\\_ai.retries](api/retries/)\\n    - [pydantic\\\\_ai.run](api/run/)\\n
        \   - [pydantic\\\\_ai.settings](api/settings/)\\n    - [pydantic\\\\_ai.tools](api/tools/)\\n    - [pydantic\\\\_ai.toolsets](api/toolsets/)\\n
        \   - [pydantic\\\\_ai.ui.ag\\\\_ui](api/ui/ag_ui/)\\n    - [pydantic\\\\_ai.ui](api/ui/base/)\\n    - [pydantic\\\\_ai.ui.vercel\\\\_ai](api/ui/vercel_ai/)\\n
        \   - [pydantic\\\\_ai.usage](api/usage/)\\n  + pydantic\\\\_evals\\n\\n\\n\\n\\n    pydantic\\\\_evals\\n    - [pydantic\\\\_evals.dataset](api/pydantic_evals/dataset/)\\n
        \   - [pydantic\\\\_evals.evaluators](api/pydantic_evals/evaluators/)\\n    - [pydantic\\\\_evals.reporting](api/pydantic_evals/reporting/)\\n
        \   - [pydantic\\\\_evals.otel](api/pydantic_evals/otel/)\\n    - [pydantic\\\\_evals.generation](api/pydantic_evals/generation/)\\n
        \ + pydantic\\\\_graph\\n\\n\\n\\n\\n    pydantic\\\\_graph\\n    - [pydantic\\\\_graph](api/pydantic_graph/graph/)\\n
        \   - [pydantic\\\\_graph.nodes](api/pydantic_graph/nodes/)\\n    - [pydantic\\\\_graph.persistence](api/pydantic_graph/persistence/)\\n
        \   - [pydantic\\\\_graph.mermaid](api/pydantic_graph/mermaid/)\\n    - [pydantic\\\\_graph.exceptions](api/pydantic_graph/exceptions/)\\n
        \   - Beta API\\n\\n\\n\\n\\n      Beta API\\n      * [pydantic\\\\_graph.beta](api/pydantic_graph/beta/)\\n      *
        [pydantic\\\\_graph.beta.graph](api/pydantic_graph/beta_graph/)\\n      * [pydantic\\\\_graph.beta.graph\\\\_builder](api/pydantic_graph/beta_graph_builder/)\\n
        \     * [pydantic\\\\_graph.beta.step](api/pydantic_graph/beta_step/)\\n      * [pydantic\\\\_graph.beta.join](api/pydantic_graph/beta_join/)\\n
        \     * [pydantic\\\\_graph.beta.decision](api/pydantic_graph/beta_decision/)\\n      * [pydantic\\\\_graph.beta.node](api/pydantic_graph/beta_node/)\\n
        \ + fasta2a\\n\\n\\n\\n\\n    fasta2a\\n    - [fasta2a](api/fasta2a/)\\n* Project\\n\\n\\n\\n\\n  Project\\n  + [Contributing](contributing/)\\n
        \ + [Upgrade Guide](changelog/)\\n  + [Version policy](version-policy/)\\n\\nTable of contents\\n\\n* [Why use Pydantic
        AI](#why-use-pydantic-ai)\\n* [Hello World Example](#hello-world-example)\\n* [Tools & Dependency Injection Example](#tools-dependency-injection-example)\\n*
        [Instrumentation with Pydantic Logfire](#instrumentation-with-pydantic-logfire)\\n* [llms.txt](#llmstxt)\\n* [Next
        Steps](#next-steps)\\n\\n# Pydantic AI\\n\\n![Pydantic AI](./img/pydantic-ai-dark.svg#only-dark)\\n\\n![Pydantic AI](./img/pydantic-ai-light.svg#only-light)\\n\\n*GenAI
        Agent Framework, the Pydantic way*\\n\\n[![CI](https://github.com/pydantic/pydantic-ai/actions/workflows/ci.yml/badge.svg?event=push)](https://github.com/pydantic/pydantic-ai/actions/workflows/ci.yml?query=branch%3Amain)\\n[![Coverage](https://coverage-badge.samuelcolvin.workers.dev/pydantic/pydantic-ai.svg)](https://coverage-badge.samuelcolvin.workers.dev/redirect/pydantic/pydantic-ai)\\n[![PyPI](https://img.shields.io/pypi/v/pydantic-ai.svg)](https://pypi.python.org/pypi/pydantic-ai)\\n[![versions](https://img.shields.io/pypi/pyversions/pydantic-ai.svg)](https://github.com/pydantic/pydantic-ai)\\n[![license](https://img.shields.io/github/license/pydantic/pydantic-ai.svg)](https://github.com/pydantic/pydantic-ai/blob/main/LICENSE)\\n[![Join
        Slack](https://img.shields.io/badge/Slack-Join%20Slack-4A154B?logo=slack)](https://logfire.pydantic.dev/docs/join-slack/)\\n\\nPydantic
        AI is a Python agent framework designed to help you\\nquickly, confidently, and painlessly build production grade
        applications and workflows with Generative AI.\\n\\nFastAPI revolutionized web development by offering an innovative
        and ergonomic design, built on the foundation of [Pydantic Validation](https://docs.pydantic.dev) and modern Python
        features like type hints.\\n\\nYet despite virtually every Python agent framework and LLM library using Pydantic Validation,
        when we began to use LLMs in [Pydantic Logfire](https://pydantic.dev/logfire), we couldn't find anything that gave
        us the same feeling.\\n\\nWe built Pydantic AI with one simple aim: to bring that FastAPI feeling to GenAI app and
        agent development.\\n\\n## Why use Pydantic AI\\n\\n1. **Built by the Pydantic Team**:\\n   [Pydantic Validation](https://docs.pydantic.dev/latest/)
        is the validation layer of the OpenAI SDK, the Google ADK, the Anthropic SDK, LangChain, LlamaIndex, AutoGPT, Transformers,
        CrewAI, Instructor and many more. *Why use the derivative when you can go straight to the source?* ![\U0001F603](https://cdn.jsdelivr.net/gh/jdecked/twemoji@16.0.1/assets/svg/1f603.svg
        \\\":smiley:\\\")\\n2. **Model-agnostic**:\\n   Supports virtually every [model](models/overview/) and provider: OpenAI,
        Anthropic, Gemini, DeepSeek, Grok, Cohere, Mistral, and Perplexity; Azure AI Foundry, Amazon Bedrock, Google Vertex
        AI, Ollama, LiteLLM, Groq, OpenRouter, Together AI, Fireworks AI, Cerebras, Hugging Face, GitHub, Heroku, Vercel,
        Nebius, OVHcloud, Alibaba Cloud, SambaNova, and Outlines. If your favorite model or provider is not listed, you can
        easily implement a [custom model](models/overview/#custom-models).\\n3. **Seamless Observability**:\\n   Tightly [integrates](logfire/)
        with [Pydantic Logfire](https://pydantic.dev/logfire), our general-purpose OpenTelemetry observability platform, for
        real-time debugging, evals-based performance monitoring, and behavior, tracing, and cost tracking. If you already
        have an observability platform that supports OTel, you can [use that too](logfire/#alternative-observability-backends).\\n4.
        **Fully Type-safe**:\\n   Designed to give your IDE or AI coding agent as much context as possible for auto-completion
        and [type checking](agents/#static-type-checking), moving entire classes of errors from runtime to write-time for
        a bit of that Rust \\\"if it compiles, it works\\\" feel.\\n5. **Powerful Evals**:\\n   Enables you to systematically
        test and [evaluate](evals/) the performance and accuracy of the agentic systems you build, and monitor the performance
        over time in Pydantic Logfire.\\n6. **MCP, A2A, and UI**:\\n   Integrates the [Model Context Protocol](mcp/overview/),
        [Agent2Agent](a2a/), and various [UI event stream](ui/overview/) standards to give your agent access to external tools
        and data, let it interoperate with other agents, and build interactive applications with streaming event-based communication.\\n7.
        **Human-in-the-Loop Tool Approval**:\\n   Easily lets you flag that certain tool calls [require approval](deferred-tools/#human-in-the-loop-tool-approval)
        before they can proceed, possibly depending on tool call arguments, conversation history, or user preferences.\\n8.
        **Durable Execution**:\\n   Enables you to build [durable agents](durable_execution/overview/) that can preserve their
        progress across transient API failures and application errors or restarts, and handle long-running, asynchronous,
        and human-in-the-loop workflows with production-grade reliability.\\n9. **Streamed Outputs**:\\n   Provides the ability
        to [stream](output/#streamed-results) structured output continuously, with immediate validation, ensuring real time
        access to generated data.\\n10. **Graph Support**:\\n    Provides a powerful way to define [graphs](graph/) using
        type hints, for use in complex applications where standard control flow can degrade to spaghetti code.\\n\\nRealistically
        though, no list is going to be as convincing as [giving it a try](#next-steps) and seeing how it makes you feel!\\n\\n**Sign
        up for our newsletter, *The Pydantic Stack*, with updates & tutorials on Pydantic AI, Logfire, and Pydantic:**\\n\\nSubscribe\\n\\n##
        Hello World Example\\n\\nHere's a minimal example of Pydantic AI:\\n\\nWith Pydantic AI GatewayDirectly to Provider
        API\\n\\n[Learn about Gateway](../gateway) hello\\\\_world.py\\n\\n```\\nfrom pydantic_ai import Agent\\n\\nagent
        = Agent(  # (1)!\\n    'gateway/anthropic:claude-sonnet-4-0',\\n    instructions='Be concise, reply with one sentence.',
        \ # (2)!\\n)\\n\\nresult = agent.run_sync('Where does \\\"hello world\\\" come from?')  # (3)!\\nprint(result.output)\\n\\\"\\\"\\\"\\nThe
        first known use of \\\"hello, world\\\" was in a 1974 textbook about the C programming language.\\n\\\"\\\"\\\"\\n```\\n\\n1.
        We configure the agent to use [Anthropic's Claude Sonnet 4.0](api/models/anthropic/) model, but you can also set the
        model when running the agent.\\n2. Register static [instructions](agents/#instructions) using a keyword argument to
        the agent.\\n3. [Run the agent](agents/#running-agents) synchronously, starting a conversation with the LLM.\\n\\nhello\\\\_world.py\\n\\n```\\nfrom
        pydantic_ai import Agent\\n\\nagent = Agent(  # (1)!\\n    'anthropic:claude-sonnet-4-0',\\n    instructions='Be concise,
        reply with one sentence.',  # (2)!\\n)\\n\\nresult = agent.run_sync('Where does \\\"hello world\\\" come from?')  #
        (3)!\\nprint(result.output)\\n\\\"\\\"\\\"\\nThe first known use of \\\"hello, world\\\" was in a 1974 textbook about
        the C programming language.\\n\\\"\\\"\\\"\\n```\\n\\n1. We configure the agent to use [Anthropic's Claude Sonnet
        4.0](api/models/anthropic/) model, but you can also set the model when running the agent.\\n2. Register static [instructions](agents/#instructions)
        using a keyword argument to the agent.\\n3. [Run the agent](agents/#running-agents) synchronously, starting a conversation
        with the LLM.\\n\\n*(This example is complete, it can be run \\\"as is\\\", assuming you've [installed the `pydantic_ai`
        package](install/))*\\n\\nThe exchange will be very short: Pydantic AI will send the instructions and the user prompt
        to the LLM, and the model will return a text response.\\n\\nNot very interesting yet, but we can easily add [tools](tools/),
        [dynamic instructions](agents/#instructions), and [structured outputs](output/) to build more powerful agents.\\n\\n##
        Tools & Dependency Injection Example\\n\\nHere is a concise example using Pydantic AI to build a support agent for
        a bank:\\n\\nWith Pydantic AI GatewayDirectly to Provider API\\n\\n[Learn about Gateway](../gateway) bank\\\\_support.py\\n\\n```\\nfrom
        dataclasses import dataclass\\n\\nfrom pydantic import BaseModel, Field\\nfrom pydantic_ai import Agent, RunContext\\n\\nfrom
        bank_database import DatabaseConn\\n\\n\\n@dataclass\\nclass SupportDependencies:  # (3)!\\n    customer_id: int\\n
        \   db: DatabaseConn  # (12)!\\n\\n\\nclass SupportOutput(BaseModel):  # (13)!\\n    support_advice: str = Field(description='Advice
        returned to the customer')\\n    block_card: bool = Field(description=\\\"Whether to block the customer's card\\\")\\n
        \   risk: int = Field(description='Risk level of query', ge=0, le=10)\\n\\n\\nsupport_agent = Agent(  # (1)!\\n    'gateway/openai:gpt-5',
        \ # (2)!\\n    deps_type=SupportDependencies,\\n    output_type=SupportOutput,  # (9)!\\n    instructions=(  # (4)!\\n
        \       'You are a support agent in our bank, give the '\\n        'customer support and judge the risk level of their
        query.'\\n    ),\\n)\\n\\n\\n@support_agent.instructions  # (5)!\\nasync def add_customer_name(ctx: RunContext[SupportDependencies])
        -> str:\\n    customer_name = await ctx.deps.db.customer_name(id=ctx.deps.customer_id)\\n    return f\\\"The customer's
        name is {customer_name!r}\\\"\\n\\n\\n@support_agent.tool  # (6)!\\nasync def customer_balance(\\n    ctx: RunContext[SupportDependencies],
        include_pending: bool\\n) -> float:\\n    \\\"\\\"\\\"Returns the customer's current account balance.\\\"\\\"\\\"
        \ # (7)!\\n    return await ctx.deps.db.customer_balance(\\n        id=ctx.deps.customer_id,\\n        include_pending=include_pending,\\n
        \   )\\n\\n\\n...  # (11)!\\n\\n\\nasync def main():\\n    deps = SupportDependencies(customer_id=123, db=DatabaseConn())\\n
        \   result = await support_agent.run('What is my balance?', deps=deps)  # (8)!\\n    print(result.output)  # (10)!\\n
        \   \\\"\\\"\\\"\\n    support_advice='Hello John, your current account balance, including pending transactions, is
        $123.45.' block_card=False risk=1\\n    \\\"\\\"\\\"\\n\\n    result = await support_agent.run('I just lost my card!',
        deps=deps)\\n    print(result.output)\\n    \\\"\\\"\\\"\\n    support_advice=\\\"I'm sorry to hear that, John. We
        are temporarily blocking your card to prevent unauthorized transactions.\\\" block_card=True risk=8\\n    \\\"\\\"\\\"\\n```\\n\\n1.
        This [agent](agents/) will act as first-tier support in a bank. Agents are generic in the type of dependencies they
        accept and the type of output they return. In this case, the support agent has type `Agent[SupportDependencies, SupportOutput]`.\\n2.
        Here we configure the agent to use [OpenAI's GPT-5 model](api/models/openai/), you can also set the model when running
        the agent.\\n3. The `SupportDependencies` dataclass is used to pass data, connections, and logic into the model that
        will be needed when running [instructions](agents/#instructions) and [tool](tools/) functions. Pydantic AI's system
        of dependency injection provides a [type-safe](agents/#static-type-checking) way to customise the behavior of your
        agents, and can be especially useful when running [unit tests](testing/) and evals.\\n4. Static [instructions](agents/#instructions)
        can be registered with the [`instructions` keyword argument](api/agent/#pydantic_ai.agent.Agent.__init__ \\\"__init__\\\")
        to the agent.\\n5. Dynamic [instructions](agents/#instructions) can be registered with the [`@agent.instructions`](api/agent/#pydantic_ai.agent.Agent.instructions
        \\\"instructions\\\") decorator, and can make use of dependency injection. Dependencies are carried via the [`RunContext`](api/tools/#pydantic_ai.tools.RunContext
        \\\"RunContext\\n\\n\\n     \\n         dataclass\\n     \\\") argument, which is parameterized with the `deps_type`
        from above. If the type annotation here is wrong, static type checkers will catch it.\\n6. The [`@agent.tool`](tools/)
        decorator let you register functions which the LLM may call while responding to a user. Again, dependencies are carried
        via [`RunContext`](api/tools/#pydantic_ai.tools.RunContext \\\"RunContext\\n\\n\\n     \\n         dataclass\\n     \\\"),
        any other arguments become the tool schema passed to the LLM. Pydantic is used to validate these arguments, and errors
        are passed back to the LLM so it can retry.\\n7. The docstring of a tool is also passed to the LLM as the description
        of the tool. Parameter descriptions are [extracted](tools/#function-tools-and-schema) from the docstring and added
        to the parameter schema sent to the LLM.\\n8. [Run the agent](agents/#running-agents) asynchronously, conducting a
        conversation with the LLM until a final response is reached. Even in this fairly simple case, the agent will exchange
        multiple messages with the LLM as tools are called to retrieve an output.\\n9. The response from the agent will be
        guaranteed to be a `SupportOutput`. If validation fails [reflection](agents/#reflection-and-self-correction), the
        agent is prompted to try again.\\n10. The output will be validated with Pydantic to guarantee it is a `SupportOutput`,
        since the agent is generic, it'll also be typed as a `SupportOutput` to aid with static type checking.\\n11. In a
        real use case, you'd add more tools and longer instructions to the agent to extend the context it's equipped with
        and support it can provide.\\n12. This is a simple sketch of a database connection, used to keep the example short
        and readable. In reality, you'd be connecting to an external database (e.g. PostgreSQL) to get information about customers.\\n13.
        This [Pydantic](https://docs.pydantic.dev) model is used to constrain the structured data returned by the agent. From
        this simple definition, Pydantic builds the JSON Schema that tells the LLM how to return the data, and performs validation
        to guarantee the data is correct at the end of the run.\\n\\nbank\\\\_support.py\\n\\n```\\nfrom dataclasses import
        dataclass\\n\\nfrom pydantic import BaseModel, Field\\nfrom pydantic_ai import Agent, RunContext\\n\\nfrom bank_database
        import DatabaseConn\\n\\n\\n@dataclass\\nclass SupportDependencies:  # (3)!\\n    customer_id: int\\n    db: DatabaseConn
        \ # (12)!\\n\\n\\nclass SupportOutput(BaseModel):  # (13)!\\n    support_advice: str = Field(description='Advice returned
        to the customer')\\n    block_card: bool = Field(description=\\\"Whether to block the customer's card\\\")\\n    risk:
        int = Field(description='Risk level of query', ge=0, le=10)\\n\\n\\nsupport_agent = Agent(  # (1)!\\n    'openai:gpt-5',
        \ # (2)!\\n    deps_type=SupportDependencies,\\n    output_type=SupportOutput,  # (9)!\\n    instructions=(  # (4)!\\n
        \       'You are a support agent in our bank, give the '\\n        'customer support and judge the risk level of their
        query.'\\n    ),\\n)\\n\\n\\n@support_agent.instructions  # (5)!\\nasync def add_customer_name(ctx: RunContext[SupportDependencies])
        -> str:\\n    customer_name = await ctx.deps.db.customer_name(id=ctx.deps.customer_id)\\n    return f\\\"The customer's
        name is {customer_name!r}\\\"\\n\\n\\n@support_agent.tool  # (6)!\\nasync def customer_balance(\\n    ctx: RunContext[SupportDependencies],
        include_pending: bool\\n) -> float:\\n    \\\"\\\"\\\"Returns the customer's current account balance.\\\"\\\"\\\"
        \ # (7)!\\n    return await ctx.deps.db.customer_balance(\\n        id=ctx.deps.customer_id,\\n        include_pending=include_pending,\\n
        \   )\\n\\n\\n...  # (11)!\\n\\n\\nasync def main():\\n    deps = SupportDependencies(customer_id=123, db=DatabaseConn())\\n
        \   result = await support_agent.run('What is my balance?', deps=deps)  # (8)!\\n    print(result.output)  # (10)!\\n
        \   \\\"\\\"\\\"\\n    support_advice='Hello John, your current account balance, including pending transactions, is
        $123.45.' block_card=False risk=1\\n    \\\"\\\"\\\"\\n\\n    result = await support_agent.run('I just lost my card!',
        deps=deps)\\n    print(result.output)\\n    \\\"\\\"\\\"\\n    support_advice=\\\"I'm sorry to hear that, John. We
        are temporarily blocking your card to prevent unauthorized transactions.\\\" block_card=True risk=8\\n    \\\"\\\"\\\"\\n```\\n\\n1.
        This [agent](agents/) will act as first-tier support in a bank. Agents are generic in the type of dependencies they
        accept and the type of output they return. In this case, the support agent has type `Agent[SupportDependencies, SupportOutput]`.\\n2.
        Here we configure the agent to use [OpenAI's GPT-5 model](api/models/openai/), you can also set the model when running
        the agent.\\n3. The `SupportDependencies` dataclass is used to pass data, connections, and logic into the model that
        will be needed when running [instructions](agents/#instructions) and [tool](tools/) functions. Pydantic AI's system
        of dependency injection provides a [type-safe](agents/#static-type-checking) way to customise the behavior of your
        agents, and can be especially useful when running [unit tests](testing/) and evals.\\n4. Static [instructions](agents/#instructions)
        can be registered with the [`instructions` keyword argument](api/agent/#pydantic_ai.agent.Agent.__init__ \\\"__init__\\\")
        to the agent.\\n5. Dynamic [instructions](agents/#instructions) can be registered with the [`@agent.instructions`](api/agent/#pydantic_ai.agent.Agent.instructions
        \\\"instructions\\\") decorator, and can make use of dependency injection. Dependencies are carried via the [`RunContext`](api/tools/#pydantic_ai.tools.RunContext
        \\\"RunContext\\n\\n\\n     \\n         dataclass\\n     \\\") argument, which is parameterized with the `deps_type`
        from above. If the type annotation here is wrong, static type checkers will catch it.\\n6. The [`@agent.tool`](tools/)
        decorator let you register functions which the LLM may call while responding to a user. Again, dependencies are carried
        via [`RunContext`](api/tools/#pydantic_ai.tools.RunContext \\\"RunContext\\n\\n\\n     \\n         dataclass\\n     \\\"),
        any other arguments become the tool schema passed to the LLM. Pydantic is used to validate these arguments, and errors
        are passed back to the LLM so it can retry.\\n7. The docstring of a tool is also passed to the LLM as the description
        of the tool. Parameter descriptions are [extracted](tools/#function-tools-and-schema) from the docstring and added
        to the parameter schema sent to the LLM.\\n8. [Run the agent](agents/#running-agents) asynchronously, conducting a
        conversation with the LLM until a final response is reached. Even in this fairly simple case, the agent will exchange
        multiple messages with the LLM as tools are called to retrieve an output.\\n9. The response from the agent will be
        guaranteed to be a `SupportOutput`. If validation fails [reflection](agents/#reflection-and-self-correction), the
        agent is prompted to try again.\\n10. The output will be validated with Pydantic to guarantee it is a `SupportOutput`,
        since the agent is generic, it'll also be typed as a `SupportOutput` to aid with static type checking.\\n11. In a
        real use case, you'd add more tools and longer instructions to the agent to extend the context it's equipped with
        and support it can provide.\\n12. This is a simple sketch of a database connection, used to keep the example short
        and readable. In reality, you'd be connecting to an external database (e.g. PostgreSQL) to get information about customers.\\n13.
        This [Pydantic](https://docs.pydantic.dev) model is used to constrain the structured data returned by the agent. From
        this simple definition, Pydantic builds the JSON Schema that tells the LLM how to return the data, and performs validation
        to guarantee the data is correct at the end of the run.\\n\\nComplete `bank_support.py` example\\n\\nThe code included
        here is incomplete for the sake of brevity (the definition of `DatabaseConn` is missing); you can find the complete
        `bank_support.py` example [here](examples/bank-support/).\\n\\n## Instrumentation with Pydantic Logfire\\n\\nEven
        a simple agent with just a handful of tools can result in a lot of back-and-forth with the LLM, making it nearly impossible
        to be confident of what's going on just from reading the code.\\nTo understand the flow of the above runs, we can
        watch the agent in action using Pydantic Logfire.\\n\\nTo do this, we need to [set up Logfire](logfire/#using-logfire),
        and add the following to our code:\\n\\nWith Pydantic AI GatewayDirectly to Provider API\\n\\n[Learn about Gateway](../gateway)
        bank\\\\_support\\\\_with\\\\_logfire.py\\n\\n```\\n...\\nfrom pydantic_ai import Agent, RunContext\\n\\nfrom bank_database
        import DatabaseConn\\n\\nimport logfire\\n\\nlogfire.configure()  # (1)!\\nlogfire.instrument_pydantic_ai()  # (2)!\\nlogfire.instrument_sqlite3()
        \ # (3)!\\n\\n...\\n\\nsupport_agent = Agent(\\n    'gateway/openai:gpt-5',\\n    deps_type=SupportDependencies,\\n
        \   output_type=SupportOutput,\\n    instructions=(\\n        'You are a support agent in our bank, give the '\\n
        \       'customer support and judge the risk level of their query.'\\n    ),\\n)\\n```\\n\\n1. Configure the Logfire
        SDK, this will fail if project is not set up.\\n2. This will instrument all Pydantic AI agents used from here on out.
        If you want to instrument only a specific agent, you can pass the [`instrument=True` keyword argument](api/agent/#pydantic_ai.agent.Agent.__init__
        \\\"__init__\\\") to the agent.\\n3. In our demo, `DatabaseConn` uses [`sqlite3`](https://docs.python.org/3/library/sqlite3.html#module-sqlite3)
        to connect to a PostgreSQL database, so [`logfire.instrument_sqlite3()`](https://logfire.pydantic.dev/docs/integrations/databases/sqlite3/)\\n
        \  is used to log the database queries.\\n\\nbank\\\\_support\\\\_with\\\\_logfire.py\\n\\n```\\n...\\nfrom pydantic_ai
        import Agent, RunContext\\n\\nfrom bank_database import DatabaseConn\\n\\nimport logfire\\n\\nlogfire.configure()
        \ # (1)!\\nlogfire.instrument_pydantic_ai()  # (2)!\\nlogfire.instrument_sqlite3()  # (3)!\\n\\n...\\n\\nsupport_agent
        = Agent(\\n    'openai:gpt-5',\\n    deps_type=SupportDependencies,\\n    output_type=SupportOutput,\\n    instructions=(\\n
        \       'You are a support agent in our bank, give the '\\n        'customer support and judge the risk level of their
        query.'\\n    ),\\n)\\n```\\n\\n1. Configure the Logfire SDK, this will fail if project is not set up.\\n2. This will
        instrument all Pydantic AI agents used from here on out. If you want to instrument only a specific agent, you can
        pass the [`instrument=True` keyword argument](api/agent/#pydantic_ai.agent.Agent.__init__ \\\"__init__\\\") to the
        agent.\\n3. In our demo, `DatabaseConn` uses [`sqlite3`](https://docs.python.org/3/library/sqlite3.html#module-sqlite3)
        to connect to a PostgreSQL database, so [`logfire.instrument_sqlite3()`](https://logfire.pydantic.dev/docs/integrations/databases/sqlite3/)\\n
        \  is used to log the database queries.\\n\\nThat's enough to get the following view of your agent in action:\\n\\nLogfire
        instrumentation for the bank agent — [View in Logfire](https://logfire-eu.pydantic.dev/public-trace/a2957caa-b7b7-4883-a529-777742649004?spanId=31aade41ab896144)\\n\\nSee
        [Monitoring and Performance](logfire/) to learn more.\\n\\n## `llms.txt`\\n\\nThe Pydantic AI documentation is available
        in the [llms.txt](https://llmstxt.org/) format.\\nThis format is defined in Markdown and suited for LLMs and AI coding
        assistants and agents.\\n\\nTwo formats are available:\\n\\n* [`llms.txt`](https://ai.pydantic.dev/llms.txt): a file
        containing a brief description\\n  of the project, along with links to the different sections of the documentation.
        The structure\\n  of this file is described in details [here](https://llmstxt.org/#format).\\n* [`llms-full.txt`](https://ai.pydantic.dev/llms-full.txt):
        Similar to the `llms.txt` file,\\n  but every link content is included. Note that this file may be too large for some
        LLMs.\\n\\nAs of today, these files are not automatically leveraged by IDEs or coding agents, but they will use it
        if you provide a link or the full text.\\n\\n## Next Steps\\n\\nTo try Pydantic AI for yourself, [install it](install/)
        and follow the instructions [in the examples](examples/setup/).\\n\\nRead the [docs](agents/) to learn more about
        building applications with Pydantic AI.\\n\\nRead the [API Reference](api/agent/) to understand Pydantic AI's interface.\\n\\nJoin
        [:simple-slack: Slack](https://logfire.pydantic.dev/docs/join-slack/) or file an issue on  [GitHub](https://github.com/pydantic/pydantic-ai/issues)
        if you have any questions.\\n\\n\\n\\n© Pydantic Services Inc. 2024 to present\"},\"title\":\"Pydantic AI\"}}}               }\n\nevent:
        content_block_stop\ndata: {\"type\":\"content_block_stop\",\"index\":2          }\n\nevent: content_block_start\ndata:
        {\"type\":\"content_block_start\",\"index\":3,\"content_block\":{\"type\":\"text\",\"text\":\"\"}   }\n\nevent: content_block_delta\ndata:
        {\"type\":\"content_block_delta\",\"index\":3,\"delta\":{\"type\":\"text_delta\",\"text\":\"P\"}               }\n\nevent:
        content_block_delta\ndata: {\"type\":\"content_block_delta\",\"index\":3,\"delta\":{\"type\":\"text_delta\",\"text\":\"ydantic
        AI is\"}      }\n\nevent: content_block_delta\ndata: {\"type\":\"content_block_delta\",\"index\":3,\"delta\":{\"type\":\"text_delta\",\"text\":\"
        a\"}}\n\nevent: content_block_delta\ndata: {\"type\":\"content_block_delta\",\"index\":3,\"delta\":{\"type\":\"text_delta\",\"text\":\"
        Python\"} }\n\nevent: content_block_delta\ndata: {\"type\":\"content_block_delta\",\"index\":3,\"delta\":{\"type\":\"text_delta\",\"text\":\"
        agent\"}            }\n\nevent: content_block_delta\ndata: {\"type\":\"content_block_delta\",\"index\":3,\"delta\":{\"type\":\"text_delta\",\"text\":\"
        framework designed\"}  }\n\nevent: content_block_delta\ndata: {\"type\":\"content_block_delta\",\"index\":3,\"delta\":{\"type\":\"text_delta\",\"text\":\"
        to help\"}         }\n\nevent: content_block_delta\ndata: {\"type\":\"content_block_delta\",\"index\":3,\"delta\":{\"type\":\"text_delta\",\"text\":\"
        you quickly\"}   }\n\nevent: content_block_delta\ndata: {\"type\":\"content_block_delta\",\"index\":3,\"delta\":{\"type\":\"text_delta\",\"text\":\",\"}
        \              }\n\nevent: content_block_delta\ndata: {\"type\":\"content_block_delta\",\"index\":3,\"delta\":{\"type\":\"text_delta\",\"text\":\"
        confid\"}   }\n\nevent: content_block_delta\ndata: {\"type\":\"content_block_delta\",\"index\":3,\"delta\":{\"type\":\"text_delta\",\"text\":\"ently,\"}
        \  }\n\nevent: content_block_delta\ndata: {\"type\":\"content_block_delta\",\"index\":3,\"delta\":{\"type\":\"text_delta\",\"text\":\"
        and pain\"}   }\n\nevent: content_block_delta\ndata: {\"type\":\"content_block_delta\",\"index\":3,\"delta\":{\"type\":\"text_delta\",\"text\":\"lessly
        build production\"}        }\n\nevent: content_block_delta\ndata: {\"type\":\"content_block_delta\",\"index\":3,\"delta\":{\"type\":\"text_delta\",\"text\":\"
        grade\"}           }\n\nevent: content_block_delta\ndata: {\"type\":\"content_block_delta\",\"index\":3,\"delta\":{\"type\":\"text_delta\",\"text\":\"
        applications\"}   }\n\nevent: content_block_delta\ndata: {\"type\":\"content_block_delta\",\"index\":3,\"delta\":{\"type\":\"text_delta\",\"text\":\"
        and\"}    }\n\nevent: content_block_delta\ndata: {\"type\":\"content_block_delta\",\"index\":3,\"delta\":{\"type\":\"text_delta\",\"text\":\"
        workflows\"}        }\n\nevent: content_block_delta\ndata: {\"type\":\"content_block_delta\",\"index\":3,\"delta\":{\"type\":\"text_delta\",\"text\":\"
        with\"}           }\n\nevent: content_block_delta\ndata: {\"type\":\"content_block_delta\",\"index\":3,\"delta\":{\"type\":\"text_delta\",\"text\":\"
        Gener\"}            }\n\nevent: content_block_delta\ndata: {\"type\":\"content_block_delta\",\"index\":3,\"delta\":{\"type\":\"text_delta\",\"text\":\"ative
        AI.\"}        }\n\nevent: content_block_stop\ndata: {\"type\":\"content_block_stop\",\"index\":3               }\n\nevent:
        message_delta\ndata: {\"type\":\"message_delta\",\"delta\":{\"stop_reason\":\"end_turn\",\"stop_sequence\":null},\"usage\":{\"input_tokens\":11749,\"cache_creation_input_tokens\":0,\"cache_read_input_tokens\":0,\"output_tokens\":161,\"server_tool_use\":{\"web_search_requests\":0,\"web_fetch_requests\":1}}
        \           }\n\nevent: message_stop\ndata: {\"type\":\"message_stop\"            }\n\n"
    headers:
      cache-control:
      - no-cache
      connection:
      - keep-alive
      content-security-policy:
      - default-src 'none'; frame-ancestors 'none'
      content-type:
      - text/event-stream; charset=utf-8
      strict-transport-security:
      - max-age=31536000; includeSubDomains; preload
      transfer-encoding:
      - chunked
    status:
      code: 200
      message: OK
version: 1
