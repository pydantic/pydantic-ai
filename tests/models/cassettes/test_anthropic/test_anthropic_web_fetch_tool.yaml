interactions:
- request:
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '362'
      content-type:
      - application/json
      host:
      - api.anthropic.com
    method: POST
    parsed_body:
      max_tokens: 4096
      messages:
      - content:
        - text: What is the first sentence on the page https://ai.pydantic.dev? Reply with only the sentence.
          type: text
        role: user
      model: claude-sonnet-4-0
      stream: false
      thinking:
        budget_tokens: 3000
        type: enabled
      tool_choice:
        type: auto
      tools:
      - name: web_fetch
        type: web_fetch_20250910
    uri: https://api.anthropic.com/v1/messages?beta=true
  response:
    headers:
      connection:
      - keep-alive
      content-length:
      - '15143'
      content-type:
      - application/json
      retry-after:
      - '17'
      strict-transport-security:
      - max-age=31536000; includeSubDomains; preload
      transfer-encoding:
      - chunked
    parsed_body:
      content:
      - signature: EuYDCkYICRgCKkBlJ/x0TrxPfSjI74R7fOSicEdm1MphCRMcS7cfV+DTdD4mSoWM+NneQg4RDDjPLAXIe7vWOX2svGEP6IkSk7HREgw0pIV0YfUDk+eb8I8aDCAklv4s9IcrmKK6eyIw+SC2R7KWo0A/CwuQ9lPKzsnVJ3a2/VnePSBSRBm+GepaOmmTxSJYISS9EHLm7eloKs0CahD6ofaKpbQ9GLdd+YF8w3DTBkJeQ48KGUWwl7wyj5A3SIibCfL97qgFnLHfKNycWlynUwFt3iw2J0xN9q9Y3JIiM7q6RmLfKzBp4J7aQ0XX881v7EST5+l3IuD0rHBA6+eQ15pkRbZBWFgpnvvc9dv0lmvSS1QdzhnfQQFunll8WOaJ+Hn6/zkpboA8q7HulOTFrf2O2/qejG5SV+aSxnsRgUOBaEMCTz/jb9s+WS3Z+mEEJuj6FAg4ntaQgZVk9ZajkS63VmWSlINZq8Bolklq5cKiqDloGx3xAa46sLHBw4Wh7xLl93R/MnshUTrBD/YjfjBXwdwA/WGTDcEPMjLDgwSGTpjJzKAnDA7Q+2EwqNyrPOTstCXw4UXTmp8Tm9FKws6G95mdiXCLwbfTeJ7dhzIIdEWosHIIHk58RZGtzSSkZiXWQsGsm/OQGAE=
        thinking: |-
          The user is asking me to fetch the first sentence from a specific URL (https://ai.pydantic.dev) and reply with only that sentence. I need to use the web_fetch tool to get the content of this page and then identify the first sentence.

          The user has provided an exact URL, so I can proceed with the web_fetch tool call.
        type: thinking
      - id: srvtoolu_017PtoV5cQYqCobig27x5882
        input:
          url: https://ai.pydantic.dev
        name: web_fetch
        type: server_tool_use
      - content:
          content:
            source:
              data: |-
                Pydantic AI
                GenAI Agent Framework, the Pydantic way
                Pydantic AI is a Python agent framework designed to help you quickly, confidently, and painlessly build production grade applications and workflows with Generative AI.
                FastAPI revolutionized web development by offering an innovative and ergonomic design, built on the foundation of [Pydantic Validation](https://docs.pydantic.dev) and modern Python features like type hints.
                Yet despite virtually every Python agent framework and LLM library using Pydantic Validation, when we began to use LLMs in [Pydantic Logfire](https://pydantic.dev/logfire), we couldn't find anything that gave us the same feeling.
                We built Pydantic AI with one simple aim: to bring that FastAPI feeling to GenAI app and agent development.
                Why use Pydantic AI
                -
                Built by the Pydantic Team:
                [Pydantic Validation](https://docs.pydantic.dev/latest/)is the validation layer of the OpenAI SDK, the Google ADK, the Anthropic SDK, LangChain, LlamaIndex, AutoGPT, Transformers, CrewAI, Instructor and many more. Why use the derivative when you can go straight to the source? -
                Model-agnostic: Supports virtually every
                [model](models/overview/)and provider: OpenAI, Anthropic, Gemini, DeepSeek, Grok, Cohere, Mistral, and Perplexity; Azure AI Foundry, Amazon Bedrock, Google Vertex AI, Ollama, LiteLLM, Groq, OpenRouter, Together AI, Fireworks AI, Cerebras, Hugging Face, GitHub, Heroku, Vercel, Nebius, OVHcloud. If your favorite model or provider is not listed, you can easily implement a[custom model](models/overview/#custom-models). -
                Seamless Observability: Tightly
                [integrates](logfire/)with[Pydantic Logfire](https://pydantic.dev/logfire), our general-purpose OpenTelemetry observability platform, for real-time debugging, evals-based performance monitoring, and behavior, tracing, and cost tracking. If you already have an observability platform that supports OTel, you can[use that too](logfire/#alternative-observability-backends). -
                Fully Type-safe: Designed to give your IDE or AI coding agent as much context as possible for auto-completion and
                [type checking](agents/#static-type-checking), moving entire classes of errors from runtime to write-time for a bit of that Rust "if it compiles, it works" feel. -
                Powerful Evals: Enables you to systematically test and
                [evaluate](evals/)the performance and accuracy of the agentic systems you build, and monitor the performance over time in Pydantic Logfire. -
                MCP, A2A, and AG-UI: Integrates the
                [Model Context Protocol](mcp/client/),[Agent2Agent](a2a/), and[AG-UI](ag-ui/)standards to give your agent access to external tools and data, let it interoperate with other agents, and build interactive applications with streaming event-based communication. -
                Human-in-the-Loop Tool Approval: Easily lets you flag that certain tool calls
                [require approval](deferred-tools/#human-in-the-loop-tool-approval)before they can proceed, possibly depending on tool call arguments, conversation history, or user preferences. -
                Durable Execution: Enables you to build
                [durable agents](durable_execution/overview/)that can preserve their progress across transient API failures and application errors or restarts, and handle long-running, asynchronous, and human-in-the-loop workflows with production-grade reliability. -
                Streamed Outputs: Provides the ability to
                [stream](output/#streamed-results)structured output continuously, with immediate validation, ensuring real time access to generated data. -
                Graph Support: Provides a powerful way to define
                [graphs](graph/)using type hints, for use in complex applications where standard control flow can degrade to spaghetti code.
                Realistically though, no list is going to be as convincing as [giving it a try](#next-steps) and seeing how it makes you feel!
                Sign up for our newsletter, The Pydantic Stack, with updates & tutorials on Pydantic AI, Logfire, and Pydantic:
                Hello World Example
                Here's a minimal example of Pydantic AI:
                from pydantic_ai import Agent
                agent = Agent( # (1)!
                'anthropic:claude-sonnet-4-0',
                instructions='Be concise, reply with one sentence.', # (2)!
                )
                result = agent.run_sync('Where does "hello world" come from?') # (3)!
                print(result.output)
                """
                The first known use of "hello, world" was in a 1974 textbook about the C programming language.
                """
                - We configure the agent to use
                [Anthropic's Claude Sonnet 4.0](api/models/anthropic/)model, but you can also set the model when running the agent. - Register static
                [instructions](agents/#instructions)using a keyword argument to the agent. [Run the agent](agents/#running-agents)synchronously, starting a conversation with the LLM.
                (This example is complete, it can be run "as is", assuming you've [installed the pydantic_ai package](install/))
                The exchange will be very short: Pydantic AI will send the instructions and the user prompt to the LLM, and the model will return a text response.
                Not very interesting yet, but we can easily add [tools](tools/), [dynamic instructions](agents/#instructions), and [structured outputs](output/) to build more powerful agents.
                Tools & Dependency Injection Example
                Here is a concise example using Pydantic AI to build a support agent for a bank:
                from dataclasses import dataclass
                from pydantic import BaseModel, Field
                from pydantic_ai import Agent, RunContext
                from bank_database import DatabaseConn
                @dataclass
                class SupportDependencies: # (3)!
                customer_id: int
                db: DatabaseConn # (12)!
                class SupportOutput(BaseModel): # (13)!
                support_advice: str = Field(description='Advice returned to the customer')
                block_card: bool = Field(description="Whether to block the customer's card")
                risk: int = Field(description='Risk level of query', ge=0, le=10)
                support_agent = Agent( # (1)!
                'openai:gpt-5', # (2)!
                deps_type=SupportDependencies,
                output_type=SupportOutput, # (9)!
                instructions=( # (4)!
                'You are a support agent in our bank, give the '
                'customer support and judge the risk level of their query.'
                ),
                )
                @support_agent.instructions # (5)!
                async def add_customer_name(ctx: RunContext[SupportDependencies]) -> str:
                customer_name = await ctx.deps.db.customer_name(id=ctx.deps.customer_id)
                return f"The customer's name is {customer_name!r}"
                @support_agent.tool # (6)!
                async def customer_balance(
                ctx: RunContext[SupportDependencies], include_pending: bool
                ) -> float:
                """Returns the customer's current account balance.""" # (7)!
                return await ctx.deps.db.customer_balance(
                id=ctx.deps.customer_id,
                include_pending=include_pending,
                )
                ... # (11)!
                async def main():
                deps = SupportDependencies(customer_id=123, db=DatabaseConn())
                result = await support_agent.run('What is my balance?', deps=deps) # (8)!
                print(result.output) # (10)!
                """
                support_advice='Hello John, your current account balance, including pending transactions, is $123.45.' block_card=False risk=1
                """
                result = await support_agent.run('I just lost my card!', deps=deps)
                print(result.output)
                """
                support_advice="I'm sorry to hear that, John. We are temporarily blocking your card to prevent unauthorized transactions." block_card=True risk=8
                """
                - This
                [agent](agents/)will act as first-tier support in a bank. Agents are generic in the type of dependencies they accept and the type of output they return. In this case, the support agent has typeAgent[SupportDependencies, SupportOutput]
                . - Here we configure the agent to use
                [OpenAI's GPT-5 model](api/models/openai/), you can also set the model when running the agent. - The
                SupportDependencies
                dataclass is used to pass data, connections, and logic into the model that will be needed when running[instructions](agents/#instructions)and[tool](tools/)functions. Pydantic AI's system of dependency injection provides a[type-safe](agents/#static-type-checking)way to customise the behavior of your agents, and can be especially useful when running[unit tests](testing/)and evals. - Static
                [instructions](agents/#instructions)can be registered with theto the agent.instructions
                keyword argument - Dynamic
                [instructions](agents/#instructions)can be registered with thedecorator, and can make use of dependency injection. Dependencies are carried via the@agent.instructions
                argument, which is parameterized with theRunContext
                deps_type
                from above. If the type annotation here is wrong, static type checkers will catch it. - The
                decorator let you register functions which the LLM may call while responding to a user. Again, dependencies are carried via@agent.tool
                , any other arguments become the tool schema passed to the LLM. Pydantic is used to validate these arguments, and errors are passed back to the LLM so it can retry.RunContext
                - The docstring of a tool is also passed to the LLM as the description of the tool. Parameter descriptions are
                [extracted](tools/#function-tools-and-schema)from the docstring and added to the parameter schema sent to the LLM. [Run the agent](agents/#running-agents)asynchronously, conducting a conversation with the LLM until a final response is reached. Even in this fairly simple case, the agent will exchange multiple messages with the LLM as tools are called to retrieve an output.- The response from the agent will be guaranteed to be a
                SupportOutput
                . If validation fails[reflection](agents/#reflection-and-self-correction), the agent is prompted to try again. - The output will be validated with Pydantic to guarantee it is a
                SupportOutput
                , since the agent is generic, it'll also be typed as aSupportOutput
                to aid with static type checking. - In a real use case, you'd add more tools and longer instructions to the agent to extend the context it's equipped with and support it can provide.
                - This is a simple sketch of a database connection, used to keep the example short and readable. In reality, you'd be connecting to an external database (e.g. PostgreSQL) to get information about customers.
                - This
                [Pydantic](https://docs.pydantic.dev)model is used to constrain the structured data returned by the agent. From this simple definition, Pydantic builds the JSON Schema that tells the LLM how to return the data, and performs validation to guarantee the data is correct at the end of the run.
                Complete bank_support.py
                example
                The code included here is incomplete for the sake of brevity (the definition of DatabaseConn
                is missing); you can find the complete bank_support.py
                example [here](examples/bank-support/).
                Instrumentation with Pydantic Logfire
                Even a simple agent with just a handful of tools can result in a lot of back-and-forth with the LLM, making it nearly impossible to be confident of what's going on just from reading the code. To understand the flow of the above runs, we can watch the agent in action using Pydantic Logfire.
                To do this, we need to [set up Logfire](logfire/#using-logfire), and add the following to our code:
                ...
                from pydantic_ai import Agent, RunContext
                from bank_database import DatabaseConn
                import logfire
                logfire.configure() # (1)!
                logfire.instrument_pydantic_ai() # (2)!
                logfire.instrument_asyncpg() # (3)!
                ...
                support_agent = Agent(
                'openai:gpt-4o',
                deps_type=SupportDependencies,
                output_type=SupportOutput,
                system_prompt=(
                'You are a support agent in our bank, give the '
                'customer support and judge the risk level of their query.'
                ),
                )
                - Configure the Logfire SDK, this will fail if project is not set up.
                - This will instrument all Pydantic AI agents used from here on out. If you want to instrument only a specific agent, you can pass the
                to the agent.instrument=True
                keyword argument - In our demo,
                DatabaseConn
                usesto connect to a PostgreSQL database, soasyncpg
                is used to log the database queries.logfire.instrument_asyncpg()
                That's enough to get the following view of your agent in action:
                See [Monitoring and Performance](logfire/) to learn more.
                llms.txt
                The Pydantic AI documentation is available in the [llms.txt](https://llmstxt.org/) format.
                This format is defined in Markdown and suited for LLMs and AI coding assistants and agents.
                Two formats are available:
                : a file containing a brief description of the project, along with links to the different sections of the documentation. The structure of this file is described in detailsllms.txt
                [here](https://llmstxt.org/#format).: Similar to thellms-full.txt
                llms.txt
                file, but every link content is included. Note that this file may be too large for some LLMs.
                As of today, these files are not automatically leveraged by IDEs or coding agents, but they will use it if you provide a link or the full text.
                Next Steps
                To try Pydantic AI for yourself, [install it](install/) and follow the instructions [in the examples](examples/setup/).
                Read the [docs](agents/) to learn more about building applications with Pydantic AI.
                Read the [API Reference](api/agent/) to understand Pydantic AI's interface.
                Join [ Slack](https://logfire.pydantic.dev/docs/join-slack/) or file an issue on [ GitHub](https://github.com/pydantic/pydantic-ai/issues) if you have any questions.
              media_type: text/plain
              type: text
            title: Pydantic AI
            type: document
          retrieved_at: '2025-10-24T21:36:01.828000+00:00'
          type: web_fetch_result
          url: https://ai.pydantic.dev
        tool_use_id: srvtoolu_017PtoV5cQYqCobig27x5882
        type: web_fetch_tool_result
      - text: Pydantic AI is a Python agent framework designed to help you quickly, confidently, and painlessly build production
          grade applications and workflows with Generative AI.
        type: text
      id: msg_01K9sy1qHejTH5PxapdMvoFU
      model: claude-sonnet-4-20250514
      role: assistant
      stop_reason: end_turn
      stop_sequence: null
      type: message
      usage:
        cache_creation:
          ephemeral_1h_input_tokens: 0
          ephemeral_5m_input_tokens: 0
        cache_creation_input_tokens: 0
        cache_read_input_tokens: 0
        input_tokens: 5471
        output_tokens: 182
        server_tool_use:
          web_fetch_requests: 1
          web_search_requests: 0
        service_tier: standard
    status:
      code: 200
      message: OK
version: 1
