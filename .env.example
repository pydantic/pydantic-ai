# Pydantic AI DevContainer Environment Variables
# Copy this file to .env and fill in your actual values

# ============================================================================
# MODEL PROVIDER API KEYS
# ============================================================================

# OpenAI (Required for: OpenAI models, OpenAI-compatible providers)
# Get your key at: https://platform.openai.com/api-keys
OPENAI_API_KEY=

# Anthropic (Required for: Claude models)
# Get your key at: https://console.anthropic.com/settings/keys
ANTHROPIC_API_KEY=

# Google Generative AI (Required for: Gemini models via Google AI Studio)
# Get your key at: https://aistudio.google.com/apikey
GEMINI_API_KEY=

# Google Cloud (Required for: Gemini models via Vertex AI)
# Service account JSON content (not a file path)
# Get it from: https://console.cloud.google.com/iam-admin/serviceaccounts
GOOGLE_SERVICE_ACCOUNT_CONTENT=

# Groq (Required for: Groq models)
# Get your key at: https://console.groq.com/keys
GROQ_API_KEY=

# Mistral AI (Required for: Mistral models)
# Get your key at: https://console.mistral.ai/api-keys
MISTRAL_API_KEY=

# Cohere (Required for: Cohere models)
# Get your key at: https://dashboard.cohere.com/api-keys
CO_API_KEY=

# AWS Bedrock (Required for: AWS Bedrock models)
# Configure via AWS CLI or set these:
# AWS_ACCESS_KEY_ID=
# AWS_SECRET_ACCESS_KEY=
# AWS_REGION=us-east-1

# ============================================================================
# ADDITIONAL MODEL PROVIDERS (OpenAI-compatible)
# ============================================================================

# DeepSeek (OpenAI-compatible)
# Get your key at: https://platform.deepseek.com/api_keys
DEEPSEEK_API_KEY=

# xAI Grok (OpenAI-compatible)
# Get your key at: https://console.x.ai/
GROK_API_KEY=

# OpenRouter (Aggregates multiple providers)
# Get your key at: https://openrouter.ai/settings/keys
OPENROUTER_API_KEY=

# Vercel AI Gateway
# Configure at: https://vercel.com/docs/ai-gateway
VERCEL_AI_GATEWAY_API_KEY=

# Fireworks AI (OpenAI-compatible)
# Get your key at: https://fireworks.ai/api-keys
FIREWORKS_API_KEY=

# Together AI (OpenAI-compatible)
# Get your key at: https://api.together.ai/settings/api-keys
TOGETHER_API_KEY=

# Cerebras (OpenAI-compatible)
# Get your key at: https://cloud.cerebras.ai/
CEREBRAS_API_KEY=

# Nebius AI (OpenAI-compatible)
# Get your key at: https://studio.nebius.ai/
NEBIUS_API_KEY=

# OVHcloud AI Endpoints (OpenAI-compatible)
# Get your key at: https://endpoints.ai.cloud.ovh.net/
OVHCLOUD_API_KEY=

# MoonshotAI (OpenAI-compatible)
# Get your key at: https://platform.moonshot.cn/
MOONSHOTAI_API_KEY=

# Heroku Inference (OpenAI-compatible)
# Get your key at: https://www.heroku.com/ai
HEROKU_INFERENCE_KEY=

# ============================================================================
# LOCAL MODEL PROVIDERS
# ============================================================================

# Ollama (Optional - for local models)
# If running Ollama locally or via docker-compose, set the base URL
# Default when using docker-compose ollama service:
# OLLAMA_BASE_URL=http://localhost:11434/v1/
# OLLAMA_API_KEY=placeholder  # Not needed for local, but some tools require it

# ============================================================================
# OBSERVABILITY & MONITORING
# ============================================================================

# Logfire (Optional - for structured logging and tracing)
# Get your token at: https://logfire.pydantic.dev/
# LOGFIRE_TOKEN=
# LOGFIRE_SERVICE_NAME=pydantic-ai-dev

# ============================================================================
# SEARCH PROVIDERS (for tool integrations)
# ============================================================================

# Brave Search (Optional - for web search tools)
# Get your key at: https://brave.com/search/api/
# BRAVE_API_KEY=

# Tavily Search (Optional - for web search tools)
# Get your key at: https://tavily.com/
# TAVILY_API_KEY=

# ============================================================================
# MODEL CONTEXT PROTOCOL (MCP)
# ============================================================================

# GitHub Personal Access Token (Optional - for MCP GitHub server)
# Create at: https://github.com/settings/tokens
# Needs: repo, read:org scopes
# GITHUB_PERSONAL_ACCESS_TOKEN=

# ============================================================================
# DATABASE CONNECTIONS (for examples)
# ============================================================================

# PostgreSQL (Optional - for SQL/RAG examples)
# Default when using docker-compose postgres service:
# DATABASE_URL=postgresql://postgres:postgres@localhost:54320/postgres

# PostgreSQL with pgvector (Optional - for RAG examples)
# Default when using docker-compose pgvector service:
# PGVECTOR_DATABASE_URL=postgresql://postgres:postgres@localhost:54321/postgres

# ============================================================================
# TESTING FLAGS
# ============================================================================

# Enable live API testing (Optional - USE WITH CAUTION - incurs API costs!)
# Set to exact value below to enable live tests that hit real APIs
# PYDANTIC_AI_LIVE_TEST_DANGEROUS=CHARGE-ME!

# ============================================================================
# NOTES
# ============================================================================
#
# - Most API keys are OPTIONAL - only set the ones you plan to use
# - For testing, use test models or Ollama to avoid API costs
# - Never commit this file with real API keys
# - Add .env to .gitignore (already done in this project)
# - See README.md for detailed setup instructions per provider
